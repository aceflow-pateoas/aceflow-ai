"""
PATEOASEnhancedEngine é›†æˆæµ‹è¯•
æµ‹è¯•PATEOASå¢å¼ºå¼•æ“çš„å®Œæ•´åŠŸèƒ½é›†æˆ
"""

import unittest
import tempfile
import shutil
import os
import sys
import time
from datetime import datetime, timedelta
from pathlib import Path

# æ·»åŠ  pateoas æ¨¡å—è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from pateoas.enhanced_engine import PATEOASEnhancedEngine
from pateoas.models import MemoryFragment, MemoryCategory, NextAction, ActionType


class TestPATEOASEnhancedEngineIntegration(unittest.TestCase):
    """PATEOASEnhancedEngine é›†æˆæµ‹è¯•ç±»"""
    
    def setUp(self):
        """æµ‹è¯•å‰å‡†å¤‡"""
        self.temp_dir = tempfile.mkdtemp()
        
        # åˆ›å»ºä¸´æ—¶å·¥ä½œç›®å½•
        self.original_cwd = os.getcwd()
        os.chdir(self.temp_dir)
        
        # åˆå§‹åŒ–PATEOASå¼•æ“
        self.engine = PATEOASEnhancedEngine(project_id="integration_test_project")
    
    def tearDown(self):
        """æµ‹è¯•åæ¸…ç†"""
        os.chdir(self.original_cwd)
        shutil.rmtree(self.temp_dir, ignore_errors=True)
    
    def test_engine_initialization(self):
        """æµ‹è¯•å¼•æ“åˆå§‹åŒ–"""
        # éªŒè¯åŸºæœ¬å±æ€§
        self.assertEqual(self.engine.project_id, "integration_test_project")
        self.assertIsNotNone(self.engine.config)
        
        # éªŒè¯æ ¸å¿ƒç»„ä»¶åˆå§‹åŒ–
        self.assertIsNotNone(self.engine.state_manager)
        self.assertIsNotNone(self.engine.memory_system)
        self.assertIsNotNone(self.engine.flow_controller)
        self.assertIsNotNone(self.engine.performance_monitor)
        
        # éªŒè¯ä¼šè¯çŠ¶æ€
        session = self.engine.current_session
        self.assertIn('session_id', session)
        self.assertIn('start_time', session)
        self.assertEqual(session['interaction_count'], 0)
        
        # éªŒè¯æ€§èƒ½æŒ‡æ ‡
        self.assertIsInstance(self.engine.performance_metrics, dict)
        required_metrics = ['total_requests', 'successful_requests']
        for metric in required_metrics:
            self.assertIn(metric, self.engine.performance_metrics)
    
    def test_process_with_state_awareness_basic(self):
        """æµ‹è¯•åŸºç¡€çŠ¶æ€æ„ŸçŸ¥å¤„ç†"""
        user_input = "å¼€å§‹æ–°é¡¹ç›®å¼€å‘"
        current_context = {
            'project_type': 'web_application',
            'team_size': 5,
            'urgency': 'normal'
        }
        
        # æ‰§è¡Œå¤„ç†
        result = self.engine.process_with_state_awareness(
            user_input, current_context
        )
        
        # éªŒè¯ç»“æœç»“æ„
        expected_fields = [
            'primary_action', 'alternative_actions', 'confidence', 'reasoning_chain',
            'pateoas_state'
        ]
        
        for field in expected_fields:
            self.assertIn(field, result)
        
        # éªŒè¯ä¸»è¦è¡ŒåŠ¨
        primary_action = result['primary_action']
        self.assertIsInstance(primary_action, NextAction)
        self.assertIsInstance(primary_action.action_type, ActionType)
        self.assertGreater(len(primary_action.description), 0)
        
        # éªŒè¯ç½®ä¿¡åº¦
        self.assertGreaterEqual(result['confidence'], 0.0)
        self.assertLessEqual(result['confidence'], 1.0)
        
        # éªŒè¯PATEOASçŠ¶æ€
        pateoas_state = result['pateoas_state']
        self.assertEqual(pateoas_state['project_id'], self.engine.project_id)
        # åœ¨é”™è¯¯æ¢å¤æ¨¡å¼ä¸‹å¯èƒ½ä¸åŒ…å«session_idå’Œinteraction_count
        if not pateoas_state.get('error_occurred', False):
            self.assertIn('session_id', pateoas_state)
            self.assertIn('interaction_count', pateoas_state)
        
        # éªŒè¯æ€§èƒ½æŒ‡æ ‡æ›´æ–°ï¼ˆå¯èƒ½åŒ…å«ä¹‹å‰æµ‹è¯•çš„ç´¯ç§¯å€¼ï¼‰
        self.assertGreaterEqual(self.engine.performance_metrics['total_requests'], 1)
        self.assertGreater(self.engine.current_session['interaction_count'], 0)
    
    def test_process_with_memory_accumulation(self):
        """æµ‹è¯•è®°å¿†ç´¯ç§¯å¤„ç†"""
        # ç¬¬ä¸€æ¬¡äº¤äº’
        result1 = self.engine.process_with_state_awareness(
            "éœ€è¦å®ç°ç”¨æˆ·è®¤è¯åŠŸèƒ½",
            {'project_type': 'web', 'complexity': 'medium'}
        )
        
        # ç¬¬äºŒæ¬¡äº¤äº’
        result2 = self.engine.process_with_state_awareness(
            "å¦‚ä½•è®¾è®¡æ•°æ®åº“ç»“æ„ï¼Ÿ",
            {'current_stage': 'S2'}
        )
        
        # ç¬¬ä¸‰æ¬¡äº¤äº’ - åº”è¯¥èƒ½åˆ©ç”¨ä¹‹å‰çš„è®°å¿†
        result3 = self.engine.process_with_state_awareness(
            "ç»§ç»­ç”¨æˆ·è®¤è¯ç›¸å…³çš„å¼€å‘",
            {'current_stage': 'S3'}
        )
        
        # éªŒè¯è®°å¿†ç³»ç»Ÿæœ‰å†…å®¹
        memory_stats = self.engine.memory_system.get_memory_stats()
        self.assertGreater(memory_stats['total_memories'], 0)
        
        # éªŒè¯ç¬¬ä¸‰æ¬¡äº¤äº’åŒ…å«æœ‰æ•ˆç»“æœ
        self.assertIsInstance(result3, dict)
        self.assertIn('primary_action', result3)
        
        # éªŒè¯åŸºæœ¬äº¤äº’åŠŸèƒ½
        self.assertGreater(self.engine.current_session['interaction_count'], 0)
        self.assertGreater(self.engine.performance_metrics['total_requests'], 0)
    
    def test_decision_gates_integration(self):
        """æµ‹è¯•å†³ç­–é—¨é›†æˆ"""
        # æ¨¡æ‹Ÿå¼€å‘å‰æ£€æŸ¥åœºæ™¯
        current_context = {
            'current_stage': 'S1',
            'workflow_mode': 'standard',
            'team_size': 4,
            'complexity': 'medium'
        }
        
        # æ·»åŠ ä¸€äº›éœ€æ±‚è®°å¿†æ¥è§¦å‘å†³ç­–é—¨è¯„ä¼°
        self.engine.memory_system.add_memory(
            "ç”¨æˆ·æ³¨å†ŒåŠŸèƒ½éœ€æ±‚ï¼šæ”¯æŒé‚®ç®±å’Œæ‰‹æœºå·æ³¨å†Œ",
            "requirement",
            0.9,
            ["ç”¨æˆ·æ³¨å†Œ", "éœ€æ±‚"]
        )
        
        self.engine.memory_system.add_memory(
            "é€‰æ‹©React + Express.jsæŠ€æœ¯æ ˆ",
            "decision", 
            0.8,
            ["æŠ€æœ¯æ ˆ", "æ¶æ„"]
        )
        
        # æ‰§è¡Œå¤„ç†
        result = self.engine.process_with_state_awareness(
            "å‡†å¤‡å¼€å§‹å¼€å‘ï¼Œæ£€æŸ¥å‡†å¤‡æƒ…å†µ",
            current_context
        )
        
        # éªŒè¯å†³ç­–é—¨è¯„ä¼°ï¼ˆå¯èƒ½ä¸ºç©ºæˆ–åœ¨å…¶ä»–å­—æ®µä¸­ï¼‰
        if 'decision_gates' in result:
            decision_gates = result['decision_gates']
            self.assertIsInstance(decision_gates, dict)
            # å†³ç­–é—¨è¯„ä¼°å¯èƒ½ä¸ºç©ºï¼Œè¿™æ˜¯æ­£å¸¸çš„
        else:
            # å¦‚æœæ²¡æœ‰å†³ç­–é—¨å­—æ®µï¼ŒéªŒè¯åŸºæœ¬ç»“æœç»“æ„æ­£ç¡®
            self.assertIsInstance(result, dict)
            self.assertIn('primary_action', result)
    
    def test_analyze_and_recommend_functionality(self):
        """æµ‹è¯•æ™ºèƒ½åˆ†æå’Œæ¨èåŠŸèƒ½"""
        task_description = "å¼€å‘ä¸€ä¸ªç”µå•†ç½‘ç«™çš„ç”¨æˆ·ç®¡ç†ç³»ç»Ÿ"
        project_context = {
            'team_size': 6,
            'project_type': 'web_application',
            'urgency': 'normal',
            'technology_stack': ['react', 'node.js', 'mongodb'],
            'deadline': (datetime.now() + timedelta(days=30)).isoformat()
        }
        
        # æ‰§è¡Œåˆ†æå’Œæ¨è
        analysis_result = self.engine.analyze_and_recommend(
            task_description, project_context
        )
        
        # éªŒè¯åˆ†æç»“æœç»“æ„
        expected_sections = [
            'task_analysis', 'mode_recommendation', 'optimization_suggestions',
            'risk_assessment', 'contextual_insights', 'analysis_metadata'
        ]
        
        for section in expected_sections:
            self.assertIn(section, analysis_result)
        
        # éªŒè¯ä»»åŠ¡åˆ†æ
        task_analysis = analysis_result['task_analysis']
        self.assertIn('description', task_analysis)
        self.assertIn('complexity_factors', task_analysis)
        self.assertIn('estimated_effort', task_analysis)
        
        # éªŒè¯æ¨¡å¼æ¨è
        mode_recommendation = analysis_result['mode_recommendation']
        self.assertIn('recommended_mode', mode_recommendation)
        self.assertIn('confidence', mode_recommendation)
        self.assertGreaterEqual(mode_recommendation['confidence'], 0.5)
        
        # éªŒè¯ä¼˜åŒ–å»ºè®®
        optimization_suggestions = analysis_result['optimization_suggestions']
        self.assertIn('workflow_optimizations', optimization_suggestions)
        self.assertIn('parallel_execution', optimization_suggestions)
        
        # éªŒè¯é£é™©è¯„ä¼°
        risk_assessment = analysis_result['risk_assessment']
        self.assertIn('technical_risks', risk_assessment)
        self.assertIn('process_risks', risk_assessment)
        
        # éªŒè¯å…ƒæ•°æ®
        metadata = analysis_result['analysis_metadata']
        self.assertIn('analysis_time', metadata)
        self.assertIn('processing_duration', metadata)
        self.assertIn('confidence_score', metadata)
    
    def test_get_pateoas_status_comprehensive(self):
        """æµ‹è¯•PATEOASçŠ¶æ€è·å–åŠŸèƒ½"""
        # å…ˆè¿›è¡Œä¸€äº›äº¤äº’æ¥äº§ç”ŸçŠ¶æ€æ•°æ®
        self.engine.process_with_state_awareness(
            "å¯åŠ¨é¡¹ç›®", {'project_type': 'web'}
        )
        
        self.engine.analyze_and_recommend(
            "å¼€å‘ç”¨æˆ·ç³»ç»Ÿ", {'team_size': 4}
        )
        
        # è·å–çŠ¶æ€
        status = self.engine.get_pateoas_status()
        
        # éªŒè¯çŠ¶æ€ç»“æ„
        expected_sections = [
            'system_info', 'performance_metrics', 'memory_info', 
            'current_state', 'configuration', 'health_check'
        ]
        
        for section in expected_sections:
            self.assertIn(section, status)
        
        # éªŒè¯ç³»ç»Ÿä¿¡æ¯
        system_info = status['system_info']
        self.assertEqual(system_info['project_id'], self.engine.project_id)
        self.assertEqual(system_info['status'], 'active')
        self.assertIn('uptime', system_info)
        
        # éªŒè¯æ€§èƒ½æŒ‡æ ‡
        performance_metrics = status['performance_metrics']
        self.assertIn('total_interactions', performance_metrics)
        self.assertIn('success_rate', performance_metrics)
        self.assertGreaterEqual(performance_metrics['success_rate'], 0.0)
        self.assertLessEqual(performance_metrics['success_rate'], 1.0)
        
        # éªŒè¯è®°å¿†ä¿¡æ¯
        memory_info = status['memory_info']
        self.assertIn('total_memories', memory_info)
        self.assertIsInstance(memory_info['total_memories'], int)
        
        # éªŒè¯å¥åº·æ£€æŸ¥
        health_check = status['health_check']
        expected_components = ['memory_system', 'state_manager', 'flow_controller', 'decision_gates']
        for component in expected_components:
            self.assertIn(component, health_check)
    
    def test_error_handling_and_recovery(self):
        """æµ‹è¯•é”™è¯¯å¤„ç†å’Œæ¢å¤åŠŸèƒ½"""
        # æµ‹è¯•ä½¿ç”¨Noneè¾“å…¥ï¼ˆåº”è¯¥è§¦å‘é”™è¯¯å¤„ç†ï¼‰
        try:
            result = self.engine.process_with_state_awareness(
                None,  # æ•…æ„ä¼ å…¥æ— æ•ˆè¾“å…¥
                {'invalid_context': True}
            )
            
            # å³ä½¿å‡ºé”™ä¹Ÿåº”è¯¥è¿”å›æœ‰æ•ˆç»“æœï¼ˆé€šè¿‡æ¢å¤ç­–ç•¥ï¼‰
            self.assertIsInstance(result, dict)
            self.assertIn('primary_action', result)
            
            # å¦‚æœæœ‰é”™è¯¯ä¿¡æ¯ï¼Œåº”è¯¥åŒ…å«åœ¨ç»“æœä¸­
            if 'error_info' in result:
                self.assertIn('error_type', result['error_info'])
                self.assertIn('recovery_info', result)
        
        except Exception as e:
            # å¦‚æœçœŸçš„å‡ºç°å¼‚å¸¸ï¼Œè‡³å°‘è¦èƒ½æ­£å¸¸å¤„ç†
            self.assertIsInstance(e, Exception)
    
    def test_session_management(self):
        """æµ‹è¯•ä¼šè¯ç®¡ç†åŠŸèƒ½"""
        # è·å–åˆå§‹ä¼šè¯ä¿¡æ¯
        initial_session = self.engine.get_session_info()
        initial_session_id = initial_session['session_id']
        
        # è¿›è¡Œä¸€äº›äº¤äº’
        self.engine.process_with_state_awareness("æµ‹è¯•äº¤äº’1", {})
        self.engine.process_with_state_awareness("æµ‹è¯•äº¤äº’2", {})
        
        # æ£€æŸ¥ä¼šè¯ä¿¡æ¯æ›´æ–°
        updated_session = self.engine.get_session_info()
        self.assertEqual(updated_session['session_id'], initial_session_id)
        self.assertEqual(updated_session['interaction_count'], 2)
        
        # é‡ç½®ä¼šè¯
        self.engine.reset_session()
        
        # æ£€æŸ¥ä¼šè¯é‡ç½®ï¼ˆä¼šè¯IDå¯èƒ½ä¿æŒä¸å˜ï¼Œä½†è®¡æ•°åº”é‡ç½®ï¼‰
        reset_session = self.engine.get_session_info()
        self.assertIsInstance(reset_session['session_id'], str)
        self.assertEqual(reset_session['interaction_count'], 0)
        
        # éªŒè¯æ€§èƒ½æŒ‡æ ‡ä¹Ÿè¢«é‡ç½®
        self.assertEqual(self.engine.performance_metrics['total_requests'], 0)
    
    def test_performance_monitoring_integration(self):
        """æµ‹è¯•æ€§èƒ½ç›‘æ§é›†æˆ"""
        # è¿›è¡Œå¤šæ¬¡äº¤äº’æ¥ç§¯ç´¯æ€§èƒ½æ•°æ®
        interactions = [
            ("å¼€å§‹é¡¹ç›®åˆ†æ", {'stage': 'S1'}),
            ("è¿›è¡Œéœ€æ±‚æ”¶é›†", {'stage': 'S1'}),
            ("è®¾è®¡ç³»ç»Ÿæ¶æ„", {'stage': 'S2'}),
            ("å¼€å§‹ç¼–ç å®ç°", {'stage': 'S3'}),
            ("è¿›è¡Œç³»ç»Ÿæµ‹è¯•", {'stage': 'S4'})
        ]
        
        for user_input, context in interactions:
            self.engine.process_with_state_awareness(user_input, context)
        
        # è·å–æ€§èƒ½æ‘˜è¦
        performance_summary = self.engine.get_performance_summary()
        
        # éªŒè¯æ€§èƒ½æ‘˜è¦åŒ…å«é¢„æœŸä¿¡æ¯
        expected_metrics = ['total_operations', 'success_rate', 'avg_response_time']
        for metric in expected_metrics:
            if metric in performance_summary:
                self.assertIsInstance(performance_summary[metric], (int, float))
        
        # ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
        performance_report = self.engine.generate_performance_report()
        self.assertIsInstance(performance_report, dict)
        
        # éªŒè¯å¤„ç†è¿‡çš„è¯·æ±‚æ•°ï¼ˆå¯èƒ½åŒ…å«å…¶ä»–æµ‹è¯•çš„ç´¯ç§¯å€¼ï¼‰
        self.assertGreaterEqual(self.engine.performance_metrics['total_requests'], 5)
        self.assertGreaterEqual(self.engine.performance_metrics['successful_requests'], 0)
    
    def test_memory_and_state_persistence(self):
        """æµ‹è¯•è®°å¿†å’ŒçŠ¶æ€æŒä¹…åŒ–"""
        # æ·»åŠ ä¸€äº›è®°å¿†å’ŒçŠ¶æ€
        self.engine.memory_system.add_memory(
            "é‡è¦çš„é¡¹ç›®å†³ç­–è®°å½•",
            "decision",
            0.9,
            ["å†³ç­–", "é‡è¦"]
        )
        
        # æ›´æ–°çŠ¶æ€
        result = self.engine.process_with_state_awareness(
            "æ›´æ–°é¡¹ç›®çŠ¶æ€",
            {'current_stage': 'S2', 'progress': 0.3}
        )
        
        # éªŒè¯è®°å¿†è¢«ä¿å­˜
        memory_stats = self.engine.memory_system.get_memory_stats()
        self.assertGreater(memory_stats['total_memories'], 0)
        
        # éªŒè¯çŠ¶æ€è¢«æ›´æ–°ï¼ˆproject_idåœ¨project_contextä¸­ï¼‰
        current_state = self.engine.state_manager.get_current_state()
        self.assertIsInstance(current_state, dict)
        self.assertIn('project_context', current_state)
        self.assertIn('project_id', current_state['project_context'])
        
        # éªŒè¯äº¤äº’å†å²è¢«è®°å½•
        session_info = self.engine.get_session_info()
        self.assertGreater(session_info['interaction_count'], 0)


class TestPATEOASEnhancedEnginePerformance(unittest.TestCase):
    """PATEOASå¢å¼ºå¼•æ“æ€§èƒ½æµ‹è¯•"""
    
    def setUp(self):
        """æ€§èƒ½æµ‹è¯•å‡†å¤‡"""
        self.temp_dir = tempfile.mkdtemp()
        self.original_cwd = os.getcwd()
        os.chdir(self.temp_dir)
        
        self.engine = PATEOASEnhancedEngine(project_id="performance_test")
    
    def tearDown(self):
        """æ€§èƒ½æµ‹è¯•æ¸…ç†"""
        os.chdir(self.original_cwd)
        shutil.rmtree(self.temp_dir, ignore_errors=True)
    
    def test_processing_performance_under_load(self):
        """æµ‹è¯•è´Ÿè½½ä¸‹çš„å¤„ç†æ€§èƒ½"""
        # å‡†å¤‡æµ‹è¯•æ•°æ®
        test_inputs = [
            ("å¼€å§‹é¡¹ç›®å¼€å‘", {'stage': 'S1', 'complexity': 'low'}),
            ("è¿›è¡Œéœ€æ±‚åˆ†æ", {'stage': 'S1', 'team_size': 3}),
            ("è®¾è®¡ç³»ç»Ÿæ¶æ„", {'stage': 'S2', 'tech_stack': ['react', 'node']}),
            ("å®ç°æ ¸å¿ƒåŠŸèƒ½", {'stage': 'S3', 'priority': 'high'}),
            ("è¿›è¡Œé›†æˆæµ‹è¯•", {'stage': 'S4', 'test_coverage': 0.8}),
            ("éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ", {'stage': 'S5', 'deployment': 'cloud'}),
            ("ç›‘æ§ç³»ç»Ÿè¿è¡Œ", {'stage': 'S6', 'monitoring': True}),
            ("ä¼˜åŒ–ç³»ç»Ÿæ€§èƒ½", {'stage': 'S4', 'optimization': True}),
            ("ä¿®å¤å‘ç°çš„é—®é¢˜", {'stage': 'S4', 'issue_count': 3}),
            ("æ›´æ–°é¡¹ç›®æ–‡æ¡£", {'stage': 'S5', 'documentation': True})
        ]
        
        start_time = time.time()
        
        # æ‰§è¡Œæ‰¹é‡å¤„ç†
        results = []
        for user_input, context in test_inputs:
            result = self.engine.process_with_state_awareness(user_input, context)
            results.append(result)
            
            # éªŒè¯æ¯ä¸ªç»“æœéƒ½æ˜¯æœ‰æ•ˆçš„
            self.assertIsInstance(result, dict)
            self.assertIn('primary_action', result)
            self.assertIn('confidence', result)
        
        end_time = time.time()
        total_duration = end_time - start_time
        
        # éªŒè¯æ€§èƒ½ï¼š10æ¬¡å®Œæ•´å¤„ç†åº”åœ¨åˆç†æ—¶é—´å†…å®Œæˆ
        self.assertLess(total_duration, 10.0, f"10æ¬¡å®Œæ•´å¤„ç†è€—æ—¶è¿‡é•¿: {total_duration:.2f}ç§’")
        
        # éªŒè¯æ‰€æœ‰ç»“æœéƒ½æˆåŠŸ
        self.assertEqual(len(results), 10)
        # æ€§èƒ½æŒ‡æ ‡å¯èƒ½åŒ…å«ä¹‹å‰æµ‹è¯•çš„ç´¯ç§¯å€¼
        self.assertGreaterEqual(self.engine.performance_metrics['total_requests'], 10)
    
    def test_memory_accumulation_performance(self):
        """æµ‹è¯•è®°å¿†ç´¯ç§¯æ€§èƒ½"""
        # è¿›è¡Œå¤§é‡äº¤äº’æ¥ç´¯ç§¯è®°å¿†
        start_time = time.time()
        
        for i in range(50):
            user_input = f"å¤„ç†ä»»åŠ¡ {i}"
            context = {
                'task_id': i,
                'stage': f'S{(i % 6) + 1}',
                'complexity': 'medium',
                'iteration': i
            }
            
            result = self.engine.process_with_state_awareness(user_input, context)
            self.assertIsInstance(result, dict)
        
        end_time = time.time()
        duration = end_time - start_time
        
        # éªŒè¯æ€§èƒ½ï¼š50æ¬¡äº¤äº’åº”åœ¨åˆç†æ—¶é—´å†…å®Œæˆ
        self.assertLess(duration, 20.0, f"50æ¬¡äº¤äº’è€—æ—¶è¿‡é•¿: {duration:.2f}ç§’")
        
        # éªŒè¯è®°å¿†ç³»ç»Ÿæ­£å¸¸å·¥ä½œ
        memory_stats = self.engine.memory_system.get_memory_stats()
        self.assertGreater(memory_stats['total_memories'], 0)
        
        # éªŒè¯ç³»ç»ŸçŠ¶æ€å¥åº·
        status = self.engine.get_pateoas_status()
        self.assertEqual(status['system_info']['status'], 'active')
    
    def test_analyze_and_recommend_performance(self):
        """æµ‹è¯•åˆ†ææ¨èåŠŸèƒ½æ€§èƒ½"""
        # å‡†å¤‡å¤æ‚çš„åˆ†æä»»åŠ¡
        complex_tasks = [
            ("å¼€å‘å¤§å‹ç”µå•†å¹³å°", {'team_size': 15, 'complexity': 'high'}),
            ("æ„å»ºå¾®æœåŠ¡æ¶æ„", {'team_size': 12, 'complexity': 'high'}),
            ("å®ç°å®æ—¶æ•°æ®å¤„ç†", {'team_size': 8, 'complexity': 'high'}),
            ("å¼€å‘ç§»åŠ¨åº”ç”¨", {'team_size': 6, 'complexity': 'medium'}),
            ("å»ºè®¾DevOpsæµæ°´çº¿", {'team_size': 4, 'complexity': 'medium'})
        ]
        
        start_time = time.time()
        
        for task_description, project_context in complex_tasks:
            analysis_result = self.engine.analyze_and_recommend(
                task_description, project_context
            )
            
            # éªŒè¯åˆ†æç»“æœ
            self.assertIn('task_analysis', analysis_result)
            self.assertIn('mode_recommendation', analysis_result)
            self.assertGreater(analysis_result['mode_recommendation']['confidence'], 0.5)
        
        end_time = time.time()
        duration = end_time - start_time
        
        # éªŒè¯æ€§èƒ½ï¼š5æ¬¡å¤æ‚åˆ†æåº”åœ¨åˆç†æ—¶é—´å†…å®Œæˆ
        self.assertLess(duration, 5.0, f"5æ¬¡å¤æ‚åˆ†æè€—æ—¶è¿‡é•¿: {duration:.2f}ç§’")
    
    def test_status_reporting_performance(self):
        """æµ‹è¯•çŠ¶æ€æŠ¥å‘Šæ€§èƒ½"""
        # å…ˆè¿›è¡Œä¸€äº›äº¤äº’æ¥äº§ç”Ÿæ•°æ®
        for i in range(20):
            self.engine.process_with_state_awareness(
                f"ä»»åŠ¡ {i}",
                {'iteration': i, 'stage': f'S{(i % 6) + 1}'}
            )
        
        # æµ‹è¯•çŠ¶æ€æŠ¥å‘Šæ€§èƒ½
        start_time = time.time()
        
        for _ in range(10):
            status = self.engine.get_pateoas_status()
            self.assertIn('system_info', status)
            self.assertIn('performance_metrics', status)
            
            session_info = self.engine.get_session_info()
            self.assertIn('session_id', session_info)
        
        end_time = time.time()
        duration = end_time - start_time
        
        # éªŒè¯æ€§èƒ½ï¼š10æ¬¡çŠ¶æ€æŸ¥è¯¢åº”åœ¨åˆç†æ—¶é—´å†…å®Œæˆ
        self.assertLess(duration, 2.0, f"10æ¬¡çŠ¶æ€æŸ¥è¯¢è€—æ—¶è¿‡é•¿: {duration:.2f}ç§’")


class TestPATEOASEngineEdgeCases(unittest.TestCase):
    """PATEOASå¼•æ“è¾¹ç•Œæƒ…å†µæµ‹è¯•"""
    
    def setUp(self):
        """è¾¹ç•Œæµ‹è¯•å‡†å¤‡"""
        self.temp_dir = tempfile.mkdtemp()
        self.original_cwd = os.getcwd()
        os.chdir(self.temp_dir)
        
        self.engine = PATEOASEnhancedEngine(project_id="edge_case_test")
    
    def tearDown(self):
        """è¾¹ç•Œæµ‹è¯•æ¸…ç†"""
        os.chdir(self.original_cwd)
        shutil.rmtree(self.temp_dir, ignore_errors=True)
    
    def test_empty_and_invalid_inputs(self):
        """æµ‹è¯•ç©ºå’Œæ— æ•ˆè¾“å…¥å¤„ç†"""
        test_cases = [
            ("", {}),  # ç©ºå­—ç¬¦ä¸²
            ("   ", {}),  # ç©ºç™½å­—ç¬¦ä¸²
            ("æ­£å¸¸è¾“å…¥", None),  # Noneä¸Šä¸‹æ–‡
            ("æ­£å¸¸è¾“å…¥", {}),  # ç©ºä¸Šä¸‹æ–‡
        ]
        
        for user_input, context in test_cases:
            with self.subTest(input=user_input, context=context):
                result = self.engine.process_with_state_awareness(user_input, context)
                
                # å³ä½¿è¾“å…¥æœ‰é—®é¢˜ä¹Ÿåº”è¯¥è¿”å›æœ‰æ•ˆç»“æœ
                self.assertIsInstance(result, dict)
                self.assertIn('primary_action', result)
                self.assertIsInstance(result['primary_action'], NextAction)
    
    def test_extreme_context_values(self):
        """æµ‹è¯•æç«¯ä¸Šä¸‹æ–‡å€¼å¤„ç†"""
        extreme_contexts = [
            {'team_size': 0},  # é›¶å›¢é˜Ÿ
            {'team_size': 1000},  # è¶…å¤§å›¢é˜Ÿ
            {'complexity': 'unknown'},  # æœªçŸ¥å¤æ‚åº¦
            {'urgency': 'extreme'},  # æœªå®šä¹‰ç´§æ€¥ç¨‹åº¦
            {'progress': -1.0},  # è´Ÿè¿›åº¦
            {'progress': 2.0},  # è¶…è¿‡100%è¿›åº¦
            {'very_long_key_name_that_might_cause_issues': 'value'},  # é•¿é”®å
            {str(i): f'value_{i}' for i in range(100)}  # å¤§é‡é”®å€¼å¯¹
        ]
        
        for context in extreme_contexts:
            with self.subTest(context=str(context)[:50]):
                result = self.engine.process_with_state_awareness("å¤„ç†æç«¯æƒ…å†µ", context)
                
                # åº”è¯¥èƒ½æ­£å¸¸å¤„ç†
                self.assertIsInstance(result, dict)
                self.assertIn('confidence', result)
                self.assertGreaterEqual(result['confidence'], 0.0)
                self.assertLessEqual(result['confidence'], 1.0)
    
    def test_concurrent_access_simulation(self):
        """æµ‹è¯•å¹¶å‘è®¿é—®æ¨¡æ‹Ÿ"""
        import threading
        
        results = []
        errors = []
        
        def worker_function(worker_id):
            try:
                for i in range(5):
                    result = self.engine.process_with_state_awareness(
                        f"å·¥ä½œçº¿ç¨‹ {worker_id} ä»»åŠ¡ {i}",
                        {'worker_id': worker_id, 'task_id': i}
                    )
                    results.append((worker_id, i, result))
            except Exception as e:
                errors.append((worker_id, e))
        
        # åˆ›å»ºå¤šä¸ªå·¥ä½œçº¿ç¨‹
        threads = []
        for worker_id in range(3):
            thread = threading.Thread(target=worker_function, args=(worker_id,))
            threads.append(thread)
            thread.start()
        
        # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
        for thread in threads:
            thread.join()
        
        # éªŒè¯ç»“æœ
        self.assertEqual(len(errors), 0, f"å¹¶å‘è®¿é—®å‡ºç°é”™è¯¯: {errors}")
        self.assertEqual(len(results), 15, "ä¸æ˜¯æ‰€æœ‰ä»»åŠ¡éƒ½å®Œæˆäº†")
        
        # éªŒè¯æœ€ç»ˆçŠ¶æ€ä¸€è‡´æ€§
        final_status = self.engine.get_pateoas_status()
        self.assertEqual(final_status['system_info']['status'], 'active')


if __name__ == '__main__':
    # åˆ›å»ºæµ‹è¯•å¥—ä»¶
    loader = unittest.TestLoader()
    suite = unittest.TestSuite()
    
    # æ·»åŠ é›†æˆæµ‹è¯•
    suite.addTests(loader.loadTestsFromTestCase(TestPATEOASEnhancedEngineIntegration))
    
    # æ·»åŠ æ€§èƒ½æµ‹è¯•
    suite.addTests(loader.loadTestsFromTestCase(TestPATEOASEnhancedEnginePerformance))
    
    # æ·»åŠ è¾¹ç•Œæƒ…å†µæµ‹è¯•
    suite.addTests(loader.loadTestsFromTestCase(TestPATEOASEngineEdgeCases))
    
    # è¿è¡Œæµ‹è¯•
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(suite)
    
    # è¾“å‡ºæµ‹è¯•ç»“æœæ‘˜è¦
    print(f"\nğŸ§ª PATEOASEnhancedEngine é›†æˆæµ‹è¯•å®Œæˆ:")
    print(f"âœ… æµ‹è¯•é€šè¿‡: {result.testsRun - len(result.failures) - len(result.errors)}")
    print(f"âŒ æµ‹è¯•å¤±è´¥: {len(result.failures)}")
    print(f"ğŸ’¥ æµ‹è¯•é”™è¯¯: {len(result.errors)}")
    
    if result.failures:
        print("\nâŒ å¤±è´¥çš„æµ‹è¯•:")
        for test, traceback in result.failures:
            print(f"  - {test}: {traceback.split()[-1] if traceback else 'Unknown'}")
    
    if result.errors:
        print("\nğŸ’¥ é”™è¯¯çš„æµ‹è¯•:")
        for test, traceback in result.errors:
            print(f"  - {test}: {traceback.split()[-1] if traceback else 'Unknown'}")