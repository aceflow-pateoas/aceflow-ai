"""
æµ‹è¯•PATEOASæ€§èƒ½ç›‘æ§ç³»ç»Ÿ
"""

from aceflow.pateoas.enhanced_engine import PATEOASEnhancedEngine
from aceflow.pateoas.performance_monitor import PATEOASPerformanceMonitor
import time
import json


def test_performance_monitoring():
    """æµ‹è¯•æ€§èƒ½ç›‘æ§åŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•PATEOASæ€§èƒ½ç›‘æ§ç³»ç»Ÿ")
    
    # 1. æµ‹è¯•æ€§èƒ½ç›‘æ§å™¨åŸºç¡€åŠŸèƒ½
    print("\n1. æµ‹è¯•æ€§èƒ½ç›‘æ§å™¨åŸºç¡€åŠŸèƒ½")
    monitor = PATEOASPerformanceMonitor("test_project")
    
    # æ¨¡æ‹Ÿæ“ä½œ
    op_id = monitor.start_operation("test_operation")
    time.sleep(0.1)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
    monitor.end_operation(op_id, "test_component", True)
    
    # è®°å½•æŒ‡æ ‡
    monitor.record_decision_accuracy(0.85)
    monitor.record_user_satisfaction(0.9)
    monitor.record_memory_efficiency(0.8)
    
    print("âœ“ åŸºç¡€åŠŸèƒ½æµ‹è¯•é€šè¿‡")
    
    # 2. æµ‹è¯•æ€§èƒ½æ‘˜è¦
    print("\n2. æµ‹è¯•æ€§èƒ½æ‘˜è¦")
    summary = monitor.get_performance_summary()
    print(f"  - æ€»è¯·æ±‚æ•°: {summary['current_metrics']['total_requests']}")
    print(f"  - ç³»ç»Ÿå¥åº·åˆ†æ•°: {summary['system_health']:.2f}")
    print(f"  - ç»„ä»¶æ•°é‡: {len(summary['component_performance'])}")
    print(f"  - è­¦æŠ¥æ•°é‡: {len(summary['alerts'])}")
    
    # 3. æµ‹è¯•é›†æˆåˆ°PATEOASEnhancedEngine
    print("\n3. æµ‹è¯•é›†æˆåˆ°PATEOASEnhancedEngine")
    engine = PATEOASEnhancedEngine('test_project')
    
    # æ‰§è¡Œå¤šæ¬¡å¤„ç†ä»¥æ”¶é›†æ€§èƒ½æ•°æ®
    for i in range(3):
        result = engine.process_with_state_awareness(
            user_input=f'æµ‹è¯•è¯·æ±‚ {i+1}',
            current_context={'test': True, 'iteration': i+1}
        )
        print(f"  - è¯·æ±‚ {i+1}: ç½®ä¿¡åº¦ {result['confidence']:.2f}")
    
    # 4. æ£€æŸ¥æ€§èƒ½æŒ‡æ ‡
    print("\n4. æ£€æŸ¥æ€§èƒ½æŒ‡æ ‡")
    performance_summary = engine.performance_monitor.get_performance_summary()
    
    print(f"  - æ€»è¯·æ±‚æ•°: {performance_summary['current_metrics']['total_requests']}")
    print(f"  - æˆåŠŸè¯·æ±‚æ•°: {performance_summary['current_metrics']['successful_requests']}")
    print(f"  - å¹³å‡å“åº”æ—¶é—´: {performance_summary['current_metrics']['average_response_time']:.3f}s")
    print(f"  - å†³ç­–å‡†ç¡®æ€§: {performance_summary['current_metrics']['decision_accuracy']:.2f}")
    print(f"  - ç³»ç»Ÿå¥åº·åˆ†æ•°: {performance_summary['system_health']:.2f}")
    
    # 5. æµ‹è¯•ç»„ä»¶æ€§èƒ½åˆ†æ
    print("\n5. ç»„ä»¶æ€§èƒ½åˆ†æ")
    for component, perf in performance_summary['component_performance'].items():
        print(f"  - {component}: æˆåŠŸç‡ {perf['success_rate']:.2%}, å¹³å‡æ—¶é—´ {perf['average_time']:.3f}s")
    
    # 6. æµ‹è¯•æ€§èƒ½æŠ¥å‘Šç”Ÿæˆ
    print("\n6. ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š")
    report = engine.performance_monitor.generate_performance_report()
    
    print(f"  - æŠ¥å‘Šæ—¶é—´æˆ³: {report['report_timestamp']}")
    print(f"  - è¶‹åŠ¿åˆ†æ: {len(report['trends'])} ä¸ªç±»åˆ«")
    print(f"  - å»ºè®®æ•°é‡: {len(report['recommendations'])}")
    
    if report['recommendations']:
        print("  - æ€§èƒ½å»ºè®®:")
        for rec in report['recommendations'][:3]:  # æ˜¾ç¤ºå‰3ä¸ªå»ºè®®
            print(f"    â€¢ {rec}")
    
    # 7. æµ‹è¯•è­¦æŠ¥ç³»ç»Ÿ
    print("\n7. æµ‹è¯•è­¦æŠ¥ç³»ç»Ÿ")
    alerts = performance_summary['alerts']
    if alerts:
        print(f"  - å‘ç° {len(alerts)} ä¸ªè­¦æŠ¥:")
        for alert in alerts:
            print(f"    â€¢ {alert['type'].upper()}: {alert['message']}")
    else:
        print("  - æ— è­¦æŠ¥ï¼Œç³»ç»Ÿè¿è¡Œæ­£å¸¸")
    
    print("\nğŸ‰ æ€§èƒ½ç›‘æ§ç³»ç»Ÿæµ‹è¯•å®Œæˆï¼")
    return True


def test_performance_thresholds():
    """æµ‹è¯•æ€§èƒ½é˜ˆå€¼å’Œè­¦æŠ¥"""
    print("\nğŸš¨ æµ‹è¯•æ€§èƒ½é˜ˆå€¼å’Œè­¦æŠ¥")
    
    monitor = PATEOASPerformanceMonitor("threshold_test")
    
    # æ¨¡æ‹Ÿé«˜å“åº”æ—¶é—´
    for i in range(5):
        op_id = monitor.start_operation("slow_operation")
        time.sleep(0.6)  # æ¨¡æ‹Ÿæ…¢æ“ä½œ
        monitor.end_operation(op_id, "slow_component", True)
    
    # æ£€æŸ¥è­¦æŠ¥
    summary = monitor.get_performance_summary()
    alerts = summary['alerts']
    
    print(f"å¹³å‡å“åº”æ—¶é—´: {summary['current_metrics']['average_response_time']:.2f}s")
    print(f"è­¦æŠ¥æ•°é‡: {len(alerts)}")
    
    for alert in alerts:
        print(f"  - {alert['type'].upper()}: {alert['message']}")
    
    return len(alerts) > 0


if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•
    success1 = test_performance_monitoring()
    success2 = test_performance_thresholds()
    
    if success1:
        print("\nâœ… ä»»åŠ¡6.3 - æ€§èƒ½ç›‘æ§å’ŒæŒ‡æ ‡ æµ‹è¯•é€šè¿‡")
    else:
        print("\nâŒ ä»»åŠ¡6.3 æµ‹è¯•å¤±è´¥")