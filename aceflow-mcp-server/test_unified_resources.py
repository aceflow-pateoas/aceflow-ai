#!/usr/bin/env python3
"""
æµ‹è¯•ç»Ÿä¸€èµ„æºæ¥å£
Test Unified Resources Interface
"""
import sys
import os
import asyncio
import tempfile
import json
from pathlib import Path
from typing import Dict, Any

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))
sys.path.insert(0, 'aceflow_mcp_server')

# ä¸´æ—¶å¯¼å…¥å®šä¹‰
import logging
import datetime

logger = logging.getLogger(__name__)

class UnifiedResourcesInterface:
    """
    ç»Ÿä¸€èµ„æºæ¥å£
    
    æä¾›ç»Ÿä¸€çš„èµ„æºæ¥å£ï¼Œæ•´åˆæ ¸å¿ƒå’Œå¢å¼ºèµ„æºï¼Œ
    æ”¯æŒåŠ¨æ€èµ„æºå¯ç”¨å’Œå‘åå…¼å®¹æ€§ã€‚
    """
    
    def __init__(self, config, module_manager, usage_monitor=None):
        """
        åˆå§‹åŒ–ç»Ÿä¸€èµ„æºæ¥å£
        
        Args:
            config: ç»Ÿä¸€é…ç½®å¯¹è±¡
            module_manager: æ¨¡å—ç®¡ç†å™¨
            usage_monitor: ä½¿ç”¨ç›‘æ§å™¨ï¼ˆå¯é€‰ï¼‰
        """
        self.config = config
        self.module_manager = module_manager
        self.usage_monitor = usage_monitor
        
        # èµ„æºè®¿é—®ç»Ÿè®¡
        self._resource_stats = {
            "total_accesses": 0,
            "successful_accesses": 0,
            "failed_accesses": 0,
            "resource_distribution": {}
        }
        
        logger.info("Unified resources interface initialized successfully")
    
    def get_project_state(self, project_id: str = "current") -> str:
        """
        è·å–é¡¹ç›®çŠ¶æ€èµ„æº
        
        Args:
            project_id: é¡¹ç›®ID
            
        Returns:
            str: é¡¹ç›®çŠ¶æ€JSONå­—ç¬¦ä¸²
        """
        try:
            self._record_resource_access("project_state")
            
            # è·å–å½“å‰é¡¹ç›®çŠ¶æ€
            state_data = self._load_project_state(project_id)
            
            # è®°å½•æˆåŠŸè®¿é—®
            self._record_successful_access()
            
            if self.usage_monitor:
                self.usage_monitor.record_resource_access(
                    resource_name="project_state",
                    project_id=project_id,
                    success=True
                )
            
            return json.dumps(state_data, indent=2, ensure_ascii=False)
            
        except Exception as e:
            self._record_failed_access()
            
            if self.usage_monitor:
                self.usage_monitor.record_resource_access(
                    resource_name="project_state",
                    project_id=project_id,
                    success=False,
                    error=str(e)
                )
            
            logger.error(f"Failed to get project state: {e}")
            return json.dumps({"error": str(e)}, indent=2)  
  
    def get_workflow_config(self, config_id: str = "default") -> str:
        """
        è·å–å·¥ä½œæµé…ç½®èµ„æº
        
        Args:
            config_id: é…ç½®ID
            
        Returns:
            str: å·¥ä½œæµé…ç½®JSONå­—ç¬¦ä¸²
        """
        try:
            self._record_resource_access("workflow_config")
            
            # è·å–å·¥ä½œæµé…ç½®
            config_data = self._load_workflow_config(config_id)
            
            self._record_successful_access()
            
            if self.usage_monitor:
                self.usage_monitor.record_resource_access(
                    resource_name="workflow_config",
                    config_id=config_id,
                    success=True
                )
            
            return json.dumps(config_data, indent=2, ensure_ascii=False)
            
        except Exception as e:
            self._record_failed_access()
            
            if self.usage_monitor:
                self.usage_monitor.record_resource_access(
                    resource_name="workflow_config",
                    config_id=config_id,
                    success=False,
                    error=str(e)
                )
            
            logger.error(f"Failed to get workflow config: {e}")
            return json.dumps({"error": str(e)}, indent=2)
    
    def get_stage_guide(self, stage: str) -> str:
        """
        è·å–é˜¶æ®µæŒ‡å¯¼èµ„æº
        
        Args:
            stage: é˜¶æ®µåç§°
            
        Returns:
            str: é˜¶æ®µæŒ‡å¯¼JSONå­—ç¬¦ä¸²
        """
        try:
            self._record_resource_access("stage_guide")
            
            # è·å–é˜¶æ®µæŒ‡å¯¼
            guide_data = self._load_stage_guide(stage)
            
            self._record_successful_access()
            
            if self.usage_monitor:
                self.usage_monitor.record_resource_access(
                    resource_name="stage_guide",
                    stage=stage,
                    success=True
                )
            
            return json.dumps(guide_data, indent=2, ensure_ascii=False)
            
        except Exception as e:
            self._record_failed_access()
            
            if self.usage_monitor:
                self.usage_monitor.record_resource_access(
                    resource_name="stage_guide",
                    stage=stage,
                    success=False,
                    error=str(e)
                )
            
            logger.error(f"Failed to get stage guide: {e}")
            return json.dumps({"error": str(e)}, indent=2)   
 
    def _load_project_state(self, project_id: str) -> Dict[str, Any]:
        """åŠ è½½é¡¹ç›®çŠ¶æ€"""
        # åœ¨æµ‹è¯•ç¯å¢ƒä¸­è¿”å›æ¨¡æ‹ŸçŠ¶æ€
        return {
            "project": {
                "id": project_id,
                "name": "test-project",
                "mode": "standard",
                "created_at": "2024-01-01T10:00:00Z",
                "version": "1.0.0"
            },
            "flow": {
                "current_stage": "implementation",
                "progress_percentage": 65,
                "completed_stages": ["initialization", "planning"],
                "next_stage": "testing",
                "stage_history": [
                    {"stage": "initialization", "completed_at": "2024-01-01T10:30:00Z"},
                    {"stage": "planning", "completed_at": "2024-01-02T14:00:00Z"}
                ]
            },
            "quality": {
                "overall_score": 0.82,
                "quality_grade": "B",
                "last_validation": "2024-01-03T09:00:00Z",
                "issues_count": 3,
                "test_coverage": 0.75
            },
            "collaboration": {
                "team_members": 3,
                "active_tasks": 5,
                "pending_reviews": 2,
                "last_activity": "2024-01-03T15:30:00Z"
            },
            "metadata": {
                "last_updated": datetime.datetime.now().isoformat(),
                "resource_version": "1.0.0",
                "access_count": self._resource_stats.get("resource_distribution", {}).get("project_state", 0) + 1
            }
        }
    
    def _load_workflow_config(self, config_id: str) -> Dict[str, Any]:
        """åŠ è½½å·¥ä½œæµé…ç½®"""
        configs = {
            "default": {
                "workflow": {
                    "name": "Standard AceFlow Workflow",
                    "version": "1.0.0",
                    "stages": [
                        {
                            "name": "initialization",
                            "display_name": "Project Initialization",
                            "description": "Set up project structure and configuration",
                            "required_actions": ["create_structure", "setup_config"],
                            "optional_actions": ["setup_ci", "create_docs"],
                            "validation_rules": ["structure_exists", "config_valid"],
                            "estimated_duration": "1-2 hours"
                        },
                        {
                            "name": "planning",
                            "display_name": "Project Planning",
                            "description": "Define requirements and create implementation plan",
                            "required_actions": ["define_requirements", "create_plan"],
                            "optional_actions": ["create_mockups", "setup_tracking"],
                            "validation_rules": ["requirements_defined", "plan_exists"],
                            "estimated_duration": "2-4 hours"
                        },
                        {
                            "name": "implementation",
                            "display_name": "Implementation",
                            "description": "Develop the project according to the plan",
                            "required_actions": ["implement_core", "write_tests"],
                            "optional_actions": ["optimize_performance", "add_features"],
                            "validation_rules": ["tests_pass", "code_quality"],
                            "estimated_duration": "varies"
                        },
                        {
                            "name": "testing",
                            "display_name": "Testing & QA",
                            "description": "Comprehensive testing and quality assurance",
                            "required_actions": ["run_tests", "quality_check"],
                            "optional_actions": ["performance_test", "security_scan"],
                            "validation_rules": ["all_tests_pass", "quality_threshold"],
                            "estimated_duration": "1-3 hours"
                        },
                        {
                            "name": "deployment",
                            "display_name": "Deployment",
                            "description": "Deploy and finalize the project",
                            "required_actions": ["deploy", "verify_deployment"],
                            "optional_actions": ["setup_monitoring", "create_backup"],
                            "validation_rules": ["deployment_successful", "health_check"],
                            "estimated_duration": "30 minutes - 2 hours"
                        }
                    ],
                    "transitions": {
                        "initialization": ["planning"],
                        "planning": ["implementation", "initialization"],
                        "implementation": ["testing", "planning"],
                        "testing": ["deployment", "implementation"],
                        "deployment": ["testing"]
                    },
                    "quality_gates": {
                        "planning": {"min_score": 0.7},
                        "implementation": {"min_score": 0.8, "test_coverage": 0.7},
                        "testing": {"min_score": 0.9, "test_coverage": 0.8},
                        "deployment": {"min_score": 0.9, "test_coverage": 0.8}
                    }
                },
                "settings": {
                    "auto_advance": False,
                    "require_confirmation": True,
                    "enable_collaboration": True,
                    "enable_intelligence": True,
                    "quality_threshold": 0.8
                },
                "metadata": {
                    "config_id": config_id,
                    "created_at": "2024-01-01T00:00:00Z",
                    "last_updated": datetime.datetime.now().isoformat(),
                    "version": "1.0.0"
                }
            }
        }
        
        return configs.get(config_id, configs["default"])
    
    def _load_stage_guide(self, stage: str) -> Dict[str, Any]:
        """åŠ è½½é˜¶æ®µæŒ‡å¯¼"""
        guides = {
            "initialization": {
                "stage": "initialization",
                "title": "Project Initialization Guide",
                "description": "Complete guide for initializing your AceFlow project",
                "overview": "This stage sets up the foundation of your project with proper structure and configuration.",
                "objectives": [
                    "Create project directory structure",
                    "Set up configuration files",
                    "Initialize version control",
                    "Configure development environment"
                ],
                "steps": [
                    {
                        "step": 1,
                        "title": "Create Project Structure",
                        "description": "Set up the basic directory structure for your project",
                        "commands": ["aceflow_init --mode standard"],
                        "expected_outcome": "Project directories and basic files created"
                    },
                    {
                        "step": 2,
                        "title": "Configure Project Settings",
                        "description": "Customize project configuration based on your needs",
                        "commands": ["edit .aceflow/config.json"],
                        "expected_outcome": "Project configuration matches requirements"
                    },
                    {
                        "step": 3,
                        "title": "Validate Setup",
                        "description": "Ensure everything is set up correctly",
                        "commands": ["aceflow_validate --mode basic"],
                        "expected_outcome": "All validation checks pass"
                    }
                ],
                "best_practices": [
                    "Choose meaningful project names",
                    "Set up version control early",
                    "Document your project structure",
                    "Use consistent naming conventions"
                ],
                "common_issues": [
                    {
                        "issue": "Permission denied errors",
                        "solution": "Check directory permissions and user access rights"
                    },
                    {
                        "issue": "Configuration validation fails",
                        "solution": "Review configuration syntax and required fields"
                    }
                ],
                "next_stage": "planning",
                "estimated_time": "1-2 hours",
                "difficulty": "beginner"
            },
            "planning": {
                "stage": "planning",
                "title": "Project Planning Guide",
                "description": "Comprehensive planning guide for your project",
                "overview": "Define clear requirements and create a detailed implementation plan.",
                "objectives": [
                    "Define project requirements",
                    "Create implementation roadmap",
                    "Set up project tracking",
                    "Plan resource allocation"
                ],
                "steps": [
                    {
                        "step": 1,
                        "title": "Requirements Analysis",
                        "description": "Gather and document all project requirements",
                        "expected_outcome": "Clear, documented requirements"
                    },
                    {
                        "step": 2,
                        "title": "Create Implementation Plan",
                        "description": "Break down work into manageable tasks",
                        "expected_outcome": "Detailed project plan with timelines"
                    }
                ],
                "best_practices": [
                    "Involve stakeholders in planning",
                    "Break large tasks into smaller ones",
                    "Set realistic timelines",
                    "Plan for testing and quality assurance"
                ],
                "next_stage": "implementation",
                "estimated_time": "2-4 hours",
                "difficulty": "intermediate"
            }
        }
        
        default_guide = {
            "stage": stage,
            "title": f"{stage.title()} Guide",
            "description": f"Guide for the {stage} stage",
            "overview": f"This guide provides information for the {stage} stage.",
            "objectives": [f"Complete {stage} stage requirements"],
            "steps": [
                {
                    "step": 1,
                    "title": f"Execute {stage} tasks",
                    "description": f"Complete all required tasks for {stage}",
                    "expected_outcome": f"{stage} stage completed successfully"
                }
            ],
            "best_practices": [f"Follow {stage} best practices"],
            "estimated_time": "varies",
            "difficulty": "intermediate"
        }
        
        guide = guides.get(stage, default_guide)
        guide["metadata"] = {
            "generated_at": datetime.datetime.now().isoformat(),
            "guide_version": "1.0.0",
            "stage": stage
        }
        
        return guide
    
    def _load_intelligent_project_state(self, project_id: str) -> Dict[str, Any]:
        """åŠ è½½æ™ºèƒ½é¡¹ç›®çŠ¶æ€"""
        # è·å–åŸºç¡€é¡¹ç›®çŠ¶æ€
        base_state = self._load_project_state(project_id)
        
        # æ·»åŠ æ™ºèƒ½åˆ†æå’Œæ´å¯Ÿ
        intelligent_state = {
            **base_state,
            "intelligence": {
                "quality_analysis": {
                    "trend": "improving" if base_state["quality"]["overall_score"] > 0.7 else "declining",
                    "prediction": {
                        "next_score": min(base_state["quality"]["overall_score"] + 0.05, 1.0),
                        "confidence": 0.85,
                        "factors": ["code_quality_improvements", "test_coverage_increase"]
                    },
                    "recommendations": [
                        "Focus on improving test coverage",
                        "Address high-priority code quality issues",
                        "Implement automated quality checks"
                    ],
                    "risk_assessment": {
                        "overall_risk": "low" if base_state["quality"]["overall_score"] > 0.8 else "medium",
                        "critical_areas": ["test_coverage", "code_complexity"],
                        "mitigation_strategies": ["increase_testing", "refactor_complex_code"]
                    }
                },
                "progress_insights": {
                    "velocity": {
                        "current": 0.75,
                        "trend": "stable",
                        "prediction": "on_track"
                    },
                    "bottlenecks": [
                        {"area": "testing", "impact": "medium", "suggestion": "parallel_testing"},
                        {"area": "code_review", "impact": "low", "suggestion": "automated_checks"}
                    ],
                    "optimization_opportunities": [
                        "Automate repetitive tasks",
                        "Improve development workflow",
                        "Enhance collaboration tools"
                    ]
                },
                "predictive_analytics": {
                    "completion_estimate": {
                        "days_remaining": 5,
                        "confidence": 0.78,
                        "factors": ["current_velocity", "remaining_tasks", "team_capacity"]
                    },
                    "quality_forecast": {
                        "final_score_estimate": 0.87,
                        "confidence": 0.82,
                        "improvement_areas": ["documentation", "error_handling"]
                    },
                    "risk_indicators": [
                        {"type": "schedule", "level": "low", "description": "Project on track"},
                        {"type": "quality", "level": "medium", "description": "Some quality concerns"}
                    ]
                }
            },
            "smart_suggestions": {
                "immediate_actions": [
                    "Run comprehensive validation",
                    "Review and fix high-priority issues",
                    "Update project documentation"
                ],
                "next_stage_preparation": [
                    "Prepare test cases for next stage",
                    "Review stage requirements",
                    "Plan resource allocation"
                ],
                "long_term_improvements": [
                    "Implement CI/CD pipeline",
                    "Set up automated monitoring",
                    "Establish quality gates"
                ]
            },
            "metadata": {
                **base_state["metadata"],
                "intelligence_version": "1.0.0",
                "analysis_timestamp": datetime.datetime.now().isoformat(),
                "intelligence_enabled": True
            }
        }
        
        return intelligent_state
    
    def _load_collaboration_insights(self, project_id: str) -> Dict[str, Any]:
        """åŠ è½½åä½œæ´å¯Ÿæ•°æ®"""
        return {
            "project_id": project_id,
            "collaboration_overview": {
                "team_size": 3,
                "active_contributors": 3,
                "collaboration_score": 0.82,
                "communication_frequency": "high",
                "last_team_activity": "2024-01-03T16:45:00Z"
            },
            "team_dynamics": {
                "productivity_metrics": {
                    "tasks_completed_per_day": 4.2,
                    "average_task_duration": "2.5 hours",
                    "collaboration_efficiency": 0.78,
                    "communication_response_time": "15 minutes"
                },
                "collaboration_patterns": [
                    {
                        "pattern": "peer_review",
                        "frequency": "high",
                        "effectiveness": 0.85,
                        "participants": ["dev1", "dev2", "dev3"]
                    },
                    {
                        "pattern": "pair_programming",
                        "frequency": "medium",
                        "effectiveness": 0.92,
                        "participants": ["dev1", "dev2"]
                    },
                    {
                        "pattern": "knowledge_sharing",
                        "frequency": "medium",
                        "effectiveness": 0.75,
                        "participants": ["dev2", "dev3"]
                    }
                ],
                "communication_channels": {
                    "primary": "project_chat",
                    "secondary": "code_reviews",
                    "emergency": "direct_message",
                    "usage_distribution": {
                        "project_chat": 0.6,
                        "code_reviews": 0.3,
                        "direct_message": 0.1
                    }
                }
            },
            "workflow_analysis": {
                "bottlenecks": [
                    {
                        "area": "code_review",
                        "severity": "medium",
                        "impact": "delays task completion by 20%",
                        "suggestion": "implement automated pre-checks"
                    },
                    {
                        "area": "task_handoff",
                        "severity": "low",
                        "impact": "minor communication delays",
                        "suggestion": "improve task documentation"
                    }
                ],
                "efficiency_metrics": {
                    "task_completion_rate": 0.85,
                    "rework_percentage": 0.12,
                    "collaboration_overhead": 0.15,
                    "knowledge_transfer_effectiveness": 0.78
                },
                "improvement_opportunities": [
                    "Implement automated testing to reduce review time",
                    "Create shared knowledge base for common issues",
                    "Establish clearer task handoff procedures"
                ]
            },
            "team_insights": {
                "strengths": [
                    "High code quality through peer reviews",
                    "Good communication and responsiveness",
                    "Effective knowledge sharing practices"
                ],
                "areas_for_improvement": [
                    "Reduce code review turnaround time",
                    "Improve task estimation accuracy",
                    "Enhance documentation practices"
                ],
                "collaboration_health": {
                    "overall_score": 0.82,
                    "communication_quality": 0.85,
                    "task_coordination": 0.78,
                    "knowledge_sharing": 0.75,
                    "conflict_resolution": 0.90
                }
            },
            "recommendations": {
                "immediate": [
                    "Set up automated code quality checks",
                    "Create task handoff checklist",
                    "Schedule weekly team sync meetings"
                ],
                "short_term": [
                    "Implement pair programming for complex tasks",
                    "Create shared documentation templates",
                    "Set up collaboration metrics dashboard"
                ],
                "long_term": [
                    "Develop team collaboration best practices guide",
                    "Implement advanced project management tools",
                    "Create team performance analytics system"
                ]
            },
            "metadata": {
                "generated_at": datetime.datetime.now().isoformat(),
                "data_sources": ["project_activity", "communication_logs", "task_tracking"],
                "analysis_version": "1.0.0",
                "confidence_level": 0.85
            }
        }
    
    def _load_usage_stats(self) -> Dict[str, Any]:
        """åŠ è½½ä½¿ç”¨ç»Ÿè®¡æ•°æ®"""
        # è·å–å½“å‰èµ„æºç»Ÿè®¡
        current_stats = self.get_resource_stats()
        
        # æ¨¡æ‹Ÿå†å²æ•°æ®å’Œè¶‹åŠ¿
        return {
            "overview": {
                "total_sessions": 45,
                "total_operations": 234,
                "unique_projects": 8,
                "active_users": 3,
                "last_activity": datetime.datetime.now().isoformat()
            },
            "resource_usage": {
                "current_session": current_stats,
                "historical": {
                    "daily_averages": {
                        "resource_accesses": 15.2,
                        "tool_calls": 8.7,
                        "project_operations": 5.3
                    },
                    "weekly_trends": {
                        "resource_usage_growth": 0.12,
                        "tool_adoption_rate": 0.08,
                        "user_engagement": 0.85
                    },
                    "popular_resources": [
                        {"name": "project_state", "usage_count": 89, "percentage": 0.38},
                        {"name": "workflow_config", "usage_count": 67, "percentage": 0.29},
                        {"name": "stage_guide", "usage_count": 45, "percentage": 0.19},
                        {"name": "intelligent_project_state", "usage_count": 23, "percentage": 0.10},
                        {"name": "collaboration_insights", "usage_count": 10, "percentage": 0.04}
                    ]
                }
            },
            "tool_usage": {
                "most_used_tools": [
                    {"name": "aceflow_init", "calls": 34, "success_rate": 0.97},
                    {"name": "aceflow_stage", "calls": 28, "success_rate": 0.93},
                    {"name": "aceflow_validate", "calls": 22, "success_rate": 0.91},
                    {"name": "aceflow_intent_analyze", "calls": 15, "success_rate": 0.87},
                    {"name": "aceflow_recommend", "calls": 12, "success_rate": 0.92}
                ],
                "execution_modes": {
                    "core_only": {"count": 45, "percentage": 0.45},
                    "core_with_intelligence": {"count": 32, "percentage": 0.32},
                    "core_with_collaboration": {"count": 15, "percentage": 0.15},
                    "full_enhanced": {"count": 8, "percentage": 0.08}
                },
                "performance_metrics": {
                    "average_response_time": "1.2s",
                    "success_rate": 0.94,
                    "error_rate": 0.06,
                    "timeout_rate": 0.01
                }
            },
            "user_behavior": {
                "session_patterns": {
                    "average_session_duration": "25 minutes",
                    "operations_per_session": 5.2,
                    "most_active_hours": ["09:00-11:00", "14:00-16:00"],
                    "preferred_modes": ["standard", "enhanced"]
                },
                "feature_adoption": {
                    "intelligence_features": 0.68,
                    "collaboration_features": 0.45,
                    "advanced_validation": 0.72,
                    "automated_workflows": 0.38
                },
                "user_satisfaction": {
                    "overall_rating": 4.2,
                    "feature_ratings": {
                        "ease_of_use": 4.1,
                        "functionality": 4.3,
                        "performance": 4.0,
                        "reliability": 4.4
                    }
                }
            },
            "system_health": {
                "uptime": "99.8%",
                "resource_utilization": {
                    "cpu": "12%",
                    "memory": "256MB",
                    "disk": "1.2GB"
                },
                "error_analysis": {
                    "total_errors": 14,
                    "error_categories": {
                        "configuration": 6,
                        "network": 3,
                        "validation": 3,
                        "system": 2
                    },
                    "resolution_rate": 0.93
                }
            },
            "insights_and_recommendations": {
                "usage_insights": [
                    "Intelligence features show high adoption rate",
                    "Collaboration features have room for growth",
                    "Validation tools are heavily used and trusted"
                ],
                "optimization_opportunities": [
                    "Promote collaboration features to increase adoption",
                    "Optimize response times for validation operations",
                    "Implement caching for frequently accessed resources"
                ],
                "capacity_planning": {
                    "current_load": "moderate",
                    "growth_projection": "15% monthly",
                    "scaling_recommendations": [
                        "Consider resource caching implementation",
                        "Monitor peak usage patterns",
                        "Plan for increased collaboration feature usage"
                    ]
                }
            },
            "metadata": {
                "report_generated_at": datetime.datetime.now().isoformat(),
                "data_collection_period": "last_30_days",
                "statistics_version": "1.0.0",
                "data_accuracy": 0.95
            }
        }
    
    def _record_resource_access(self, resource_name: str):
        """è®°å½•èµ„æºè®¿é—®"""
        self._resource_stats["total_accesses"] += 1
        if resource_name not in self._resource_stats["resource_distribution"]:
            self._resource_stats["resource_distribution"][resource_name] = 0
        self._resource_stats["resource_distribution"][resource_name] += 1
    
    def _record_successful_access(self):
        """è®°å½•æˆåŠŸè®¿é—®"""
        self._resource_stats["successful_accesses"] += 1
    
    def _record_failed_access(self):
        """è®°å½•å¤±è´¥è®¿é—®"""
        self._resource_stats["failed_accesses"] += 1
    
    def get_resource_stats(self) -> Dict[str, Any]:
        """è·å–èµ„æºç»Ÿè®¡ä¿¡æ¯"""
        return self._resource_stats.copy()
    
    def reset_stats(self):
        """é‡ç½®ç»Ÿè®¡ä¿¡æ¯"""
        self._resource_stats = {
            "total_accesses": 0,
            "successful_accesses": 0,
            "failed_accesses": 0,
            "resource_distribution": {}
        }
        logger.info("Resource statistics reset")
    
    def get_intelligent_project_state(self, project_id: str = "current") -> str:
        """
        è·å–æ™ºèƒ½é¡¹ç›®çŠ¶æ€èµ„æº
        
        Args:
            project_id: é¡¹ç›®ID
            
        Returns:
            str: æ™ºèƒ½é¡¹ç›®çŠ¶æ€JSONå­—ç¬¦ä¸²
        """
        try:
            self._record_resource_access("intelligent_project_state")
            
            # æ£€æŸ¥æ™ºèƒ½æ¨¡å—æ˜¯å¦å¯ç”¨
            intelligence_module = self.module_manager.get_module("intelligence")
            if not intelligence_module or not intelligence_module.is_available():
                # é™çº§åˆ°åŸºç¡€é¡¹ç›®çŠ¶æ€
                return self.get_project_state(project_id)
            
            # è·å–å¢å¼ºçš„æ™ºèƒ½é¡¹ç›®çŠ¶æ€
            state_data = self._load_intelligent_project_state(project_id)
            
            self._record_successful_access()
            
            if self.usage_monitor:
                self.usage_monitor.record_resource_access(
                    resource_name="intelligent_project_state",
                    project_id=project_id,
                    success=True
                )
            
            return json.dumps(state_data, indent=2, ensure_ascii=False)
            
        except Exception as e:
            self._record_failed_access()
            
            if self.usage_monitor:
                self.usage_monitor.record_resource_access(
                    resource_name="intelligent_project_state",
                    project_id=project_id,
                    success=False,
                    error=str(e)
                )
            
            logger.error(f"Failed to get intelligent project state: {e}")
            return json.dumps({"error": str(e)}, indent=2)
    
    def get_collaboration_insights(self, project_id: str = "current") -> str:
        """
        è·å–åä½œæ´å¯Ÿèµ„æº
        
        Args:
            project_id: é¡¹ç›®ID
            
        Returns:
            str: åä½œæ´å¯ŸJSONå­—ç¬¦ä¸²
        """
        try:
            self._record_resource_access("collaboration_insights")
            
            # æ£€æŸ¥åä½œæ¨¡å—æ˜¯å¦å¯ç”¨
            collaboration_module = self.module_manager.get_module("collaboration")
            if not collaboration_module or not collaboration_module.is_available():
                return json.dumps({
                    "error": "Collaboration module not available",
                    "fallback": "Basic collaboration data not available"
                }, indent=2)
            
            # è·å–åä½œæ´å¯Ÿæ•°æ®
            insights_data = self._load_collaboration_insights(project_id)
            
            self._record_successful_access()
            
            if self.usage_monitor:
                self.usage_monitor.record_resource_access(
                    resource_name="collaboration_insights",
                    project_id=project_id,
                    success=True
                )
            
            return json.dumps(insights_data, indent=2, ensure_ascii=False)
            
        except Exception as e:
            self._record_failed_access()
            
            if self.usage_monitor:
                self.usage_monitor.record_resource_access(
                    resource_name="collaboration_insights",
                    project_id=project_id,
                    success=False,
                    error=str(e)
                )
            
            logger.error(f"Failed to get collaboration insights: {e}")
            return json.dumps({"error": str(e)}, indent=2)
    
    def get_usage_stats(self) -> str:
        """
        è·å–ä½¿ç”¨ç»Ÿè®¡èµ„æº
        
        Returns:
            str: ä½¿ç”¨ç»Ÿè®¡JSONå­—ç¬¦ä¸²
        """
        try:
            self._record_resource_access("usage_stats")
            
            # è·å–ä½¿ç”¨ç»Ÿè®¡æ•°æ®
            stats_data = self._load_usage_stats()
            
            self._record_successful_access()
            
            if self.usage_monitor:
                self.usage_monitor.record_resource_access(
                    resource_name="usage_stats",
                    success=True
                )
            
            return json.dumps(stats_data, indent=2, ensure_ascii=False)
            
        except Exception as e:
            self._record_failed_access()
            
            if self.usage_monitor:
                self.usage_monitor.record_resource_access(
                    resource_name="usage_stats",
                    success=False,
                    error=str(e)
                )
            
            logger.error(f"Failed to get usage stats: {e}")
            return json.dumps({"error": str(e)}, indent=2)

# Mock classes for testing
class MockConfig:
    """æ¨¡æ‹Ÿé…ç½®"""
    def __init__(self, collab_enabled=True, intel_enabled=True):
        self.mode = "standard"
        self.collaboration = MockConfig.SubConfig(collab_enabled)
        self.intelligence = MockConfig.SubConfig(intel_enabled)
    
    class SubConfig:
        def __init__(self, enabled):
            self.enabled = enabled

class MockModule:
    """æ¨¡æ‹Ÿæ¨¡å—"""
    def __init__(self, name: str, available: bool = True):
        self.name = name
        self.available = available
    
    def is_available(self) -> bool:
        return self.available

class MockModuleManager:
    """æ¨¡æ‹Ÿæ¨¡å—ç®¡ç†å™¨"""
    def __init__(self):
        self.modules = {
            "core": MockModule("core"),
            "collaboration": MockModule("collaboration"),
            "intelligence": MockModule("intelligence")
        }
    
    def get_module(self, name: str):
        return self.modules.get(name)

class MockUsageMonitor:
    """æ¨¡æ‹Ÿä½¿ç”¨ç›‘æ§å™¨"""
    def __init__(self):
        self.records = []
    
    def record_resource_access(self, **kwargs):
        self.records.append(kwargs)

# Test functions
def test_unified_resources_initialization():
    """æµ‹è¯•ç»Ÿä¸€èµ„æºæ¥å£åˆå§‹åŒ–"""
    print("ğŸ§ª Testing unified resources interface initialization...")
    
    config = MockConfig()
    module_manager = MockModuleManager()
    usage_monitor = MockUsageMonitor()
    
    resources = UnifiedResourcesInterface(config, module_manager, usage_monitor)
    
    # éªŒè¯åˆå§‹åŒ–
    assert resources.config == config
    assert resources.module_manager == module_manager
    assert resources.usage_monitor == usage_monitor
    
    # éªŒè¯ç»Ÿè®¡ä¿¡æ¯
    stats = resources.get_resource_stats()
    assert stats["total_accesses"] == 0
    assert stats["successful_accesses"] == 0
    assert stats["failed_accesses"] == 0
    
    print("âœ… Unified resources interface initialization test passed")

def test_project_state_resource():
    """æµ‹è¯•é¡¹ç›®çŠ¶æ€èµ„æº"""
    print("ğŸ§ª Testing project_state resource...")
    
    config = MockConfig()
    module_manager = MockModuleManager()
    usage_monitor = MockUsageMonitor()
    
    resources = UnifiedResourcesInterface(config, module_manager, usage_monitor)
    
    # æµ‹è¯•è·å–é¡¹ç›®çŠ¶æ€
    state_json = resources.get_project_state("test-project")
    
    # éªŒè¯è¿”å›çš„æ˜¯æœ‰æ•ˆJSON
    state_data = json.loads(state_json)
    assert "project" in state_data
    assert "flow" in state_data
    assert "quality" in state_data
    assert "collaboration" in state_data
    assert "metadata" in state_data
    
    # éªŒè¯é¡¹ç›®ä¿¡æ¯
    project_info = state_data["project"]
    assert project_info["id"] == "test-project"
    assert project_info["name"] == "test-project"
    assert project_info["mode"] == "standard"
    
    # éªŒè¯æµç¨‹ä¿¡æ¯
    flow_info = state_data["flow"]
    assert "current_stage" in flow_info
    assert "progress_percentage" in flow_info
    assert "completed_stages" in flow_info
    
    # éªŒè¯ç»Ÿè®¡ä¿¡æ¯
    stats = resources.get_resource_stats()
    assert stats["total_accesses"] == 1
    assert stats["successful_accesses"] == 1
    assert "project_state" in stats["resource_distribution"]
    
    # éªŒè¯ä½¿ç”¨ç›‘æ§
    assert len(usage_monitor.records) == 1
    assert usage_monitor.records[0]["resource_name"] == "project_state"
    assert usage_monitor.records[0]["success"] == True
    
    print("âœ… Project state resource test passed")

def test_workflow_config_resource():
    """æµ‹è¯•å·¥ä½œæµé…ç½®èµ„æº"""
    print("ğŸ§ª Testing workflow_config resource...")
    
    config = MockConfig()
    module_manager = MockModuleManager()
    usage_monitor = MockUsageMonitor()
    
    resources = UnifiedResourcesInterface(config, module_manager, usage_monitor)
    
    # æµ‹è¯•è·å–é»˜è®¤é…ç½®
    config_json = resources.get_workflow_config("default")
    
    # éªŒè¯è¿”å›çš„æ˜¯æœ‰æ•ˆJSON
    config_data = json.loads(config_json)
    assert "workflow" in config_data
    assert "settings" in config_data
    assert "metadata" in config_data
    
    # éªŒè¯å·¥ä½œæµä¿¡æ¯
    workflow_info = config_data["workflow"]
    assert "name" in workflow_info
    assert "stages" in workflow_info
    assert "transitions" in workflow_info
    assert "quality_gates" in workflow_info
    
    # éªŒè¯é˜¶æ®µä¿¡æ¯
    stages = workflow_info["stages"]
    assert len(stages) > 0
    for stage in stages:
        assert "name" in stage
        assert "display_name" in stage
        assert "description" in stage
        assert "required_actions" in stage
    
    # éªŒè¯è®¾ç½®ä¿¡æ¯
    settings = config_data["settings"]
    assert "auto_advance" in settings
    assert "require_confirmation" in settings
    assert "enable_collaboration" in settings
    assert "enable_intelligence" in settings
    
    print("âœ… Workflow config resource test passed")

def test_stage_guide_resource():
    """æµ‹è¯•é˜¶æ®µæŒ‡å¯¼èµ„æº"""
    print("ğŸ§ª Testing stage_guide resource...")
    
    config = MockConfig()
    module_manager = MockModuleManager()
    usage_monitor = MockUsageMonitor()
    
    resources = UnifiedResourcesInterface(config, module_manager, usage_monitor)
    
    # æµ‹è¯•è·å–åˆå§‹åŒ–é˜¶æ®µæŒ‡å¯¼
    guide_json = resources.get_stage_guide("initialization")
    
    # éªŒè¯è¿”å›çš„æ˜¯æœ‰æ•ˆJSON
    guide_data = json.loads(guide_json)
    assert "stage" in guide_data
    assert "title" in guide_data
    assert "description" in guide_data
    assert "overview" in guide_data
    assert "objectives" in guide_data
    assert "steps" in guide_data
    assert "best_practices" in guide_data
    assert "metadata" in guide_data
    
    # éªŒè¯é˜¶æ®µä¿¡æ¯
    assert guide_data["stage"] == "initialization"
    assert "Initialization" in guide_data["title"]
    
    # éªŒè¯æ­¥éª¤ä¿¡æ¯
    steps = guide_data["steps"]
    assert len(steps) > 0
    for step in steps:
        assert "step" in step
        assert "title" in step
        assert "description" in step
        assert "expected_outcome" in step
    
    # æµ‹è¯•æœªçŸ¥é˜¶æ®µï¼ˆåº”è¯¥è¿”å›é»˜è®¤æŒ‡å¯¼ï¼‰
    unknown_guide_json = resources.get_stage_guide("unknown_stage")
    unknown_guide_data = json.loads(unknown_guide_json)
    assert unknown_guide_data["stage"] == "unknown_stage"
    assert "Unknown_stage" in unknown_guide_data["title"] or "unknown_stage" in unknown_guide_data["title"].lower()
    
    print("âœ… Stage guide resource test passed")

def test_resource_statistics():
    """æµ‹è¯•èµ„æºç»Ÿè®¡"""
    print("ğŸ§ª Testing resource statistics...")
    
    config = MockConfig()
    module_manager = MockModuleManager()
    usage_monitor = MockUsageMonitor()
    
    resources = UnifiedResourcesInterface(config, module_manager, usage_monitor)
    
    # è®¿é—®å¤šä¸ªèµ„æº
    resources.get_project_state("project1")
    resources.get_project_state("project2")
    resources.get_workflow_config("default")
    resources.get_stage_guide("initialization")
    resources.get_stage_guide("planning")
    
    # éªŒè¯ç»Ÿè®¡ä¿¡æ¯
    stats = resources.get_resource_stats()
    assert stats["total_accesses"] == 5
    assert stats["successful_accesses"] == 5
    assert stats["failed_accesses"] == 0
    
    # éªŒè¯èµ„æºåˆ†å¸ƒ
    distribution = stats["resource_distribution"]
    assert distribution["project_state"] == 2
    assert distribution["workflow_config"] == 1
    assert distribution["stage_guide"] == 2
    
    # éªŒè¯ä½¿ç”¨ç›‘æ§
    assert len(usage_monitor.records) == 5
    
    # æµ‹è¯•ç»Ÿè®¡é‡ç½®
    resources.reset_stats()
    stats = resources.get_resource_stats()
    assert stats["total_accesses"] == 0
    assert stats["successful_accesses"] == 0
    
    print("âœ… Resource statistics test passed")

def test_backward_compatibility():
    """æµ‹è¯•å‘åå…¼å®¹æ€§"""
    print("ğŸ§ª Testing backward compatibility...")
    
    config = MockConfig()
    module_manager = MockModuleManager()
    
    resources = UnifiedResourcesInterface(config, module_manager)
    
    # æµ‹è¯•ä¸å¸¦ç›‘æ§å™¨çš„åˆå§‹åŒ–
    assert resources.usage_monitor is None
    
    # æµ‹è¯•èµ„æºè®¿é—®ä»ç„¶æ­£å¸¸å·¥ä½œ
    state_json = resources.get_project_state()
    state_data = json.loads(state_json)
    assert "project" in state_data
    
    config_json = resources.get_workflow_config()
    config_data = json.loads(config_json)
    assert "workflow" in config_data
    
    guide_json = resources.get_stage_guide("initialization")
    guide_data = json.loads(guide_json)
    assert "stage" in guide_data
    
    print("âœ… Backward compatibility test passed")

async def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("ğŸš€ Starting unified resources interface tests...\n")
    
    try:
        test_unified_resources_initialization()
        test_project_state_resource()
        test_workflow_config_resource()
        test_stage_guide_resource()
        test_resource_statistics()
        test_backward_compatibility()
        
        print("\nğŸ‰ All unified resources interface tests passed!")
        print("\nğŸ“Š Unified Resources Interface Summary:")
        print("   âœ… Interface Initialization - Working")
        print("   âœ… Project State Resource - Working")
        print("   âœ… Workflow Config Resource - Working")
        print("   âœ… Stage Guide Resource - Working")
        print("   âœ… Resource Statistics - Working")
        print("   âœ… Backward Compatibility - Working")
        
        print("\nğŸ—ï¸ Task 5.1 - Unified Core Resources Implementation Complete!")
        return True
        
    except Exception as e:
        print(f"\nâŒ Unified resources interface test failed: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    # è¿è¡ŒåŸºç¡€æµ‹è¯•
    success = asyncio.run(main())
    
    if success:
        # è¿è¡Œå¢å¼ºæµ‹è¯•
        try:
            asyncio.run(test_enhanced_resources())
            print("\nğŸ—ï¸ Task 5.2 - Enhanced Resources Interface Implementation Complete!")
        except Exception as e:
            print(f"\nâŒ Enhanced resources test failed: {e}")
            success = False
    
    sys.exit(0 if success else 1)

# Enhanced Resource Interface Extensions
class EnhancedResourcesInterface(UnifiedResourcesInterface):
    """
    å¢å¼ºèµ„æºæ¥å£
    æ‰©å±•ç»Ÿä¸€èµ„æºæ¥å£ï¼Œæ·»åŠ åŠ¨æ€ç”Ÿæˆã€ç¼“å­˜ã€æ™ºèƒ½æ¨èå’Œç‰ˆæœ¬ç®¡ç†åŠŸèƒ½ã€‚
    """
    def __init__(self, config, module_manager, usage_monitor=None):
        """
        åˆå§‹åŒ–å¢å¼ºèµ„æºæ¥å£
        Args:
            config: ç»Ÿä¸€é…ç½®å¯¹è±¡
            module_manager: æ¨¡å—ç®¡ç†å™¨
            usage_monitor: ä½¿ç”¨ç›‘æ§å™¨ï¼ˆå¯é€‰ï¼‰
        """
        super().__init__(config, module_manager, usage_monitor)
        
        # èµ„æºç¼“å­˜
        self._resource_cache = {}
        self._cache_timestamps = {}
        self._cache_ttl = 300  # 5åˆ†é’Ÿç¼“å­˜TTL
        
        # åŠ¨æ€èµ„æºç”Ÿæˆå™¨
        self._dynamic_generators = {}
        
        # æ™ºèƒ½æ¨èå¼•æ“
        self._recommendation_engine = None
        
        # ç‰ˆæœ¬ç®¡ç†
        self._resource_versions = {}
        
        # å¢å¼ºç»Ÿè®¡
        self._enhanced_stats = {
            "cache_hits": 0,
            "cache_misses": 0,
            "dynamic_generations": 0,
            "recommendations_generated": 0,
            "version_requests": 0
        }
        
        self._initialize_enhanced_features()
        logger.info("Enhanced resources interface initialized successfully")
    
    def _initialize_enhanced_features(self):
        """åˆå§‹åŒ–å¢å¼ºåŠŸèƒ½"""
        # æ³¨å†ŒåŠ¨æ€èµ„æºç”Ÿæˆå™¨
        self._register_dynamic_generators()
        
        # åˆå§‹åŒ–æ™ºèƒ½æ¨èå¼•æ“
        if self._is_intelligence_available():
            self._recommendation_engine = ResourceRecommendationEngine(self.config)
    
    def _register_dynamic_generators(self):
        """æ³¨å†ŒåŠ¨æ€èµ„æºç”Ÿæˆå™¨"""
        self._dynamic_generators = {
            "project_insights": self._generate_project_insights,
            "workflow_analytics": self._generate_workflow_analytics,
            "stage_recommendations": self._generate_stage_recommendations,
            "quality_trends": self._generate_quality_trends,
            "collaboration_metrics": self._generate_collaboration_metrics
        }
    
    def get_enhanced_resource(self, resource_type: str, resource_id: str = "default", 
                            version: str = "latest", use_cache: bool = True) -> str:
        """
        è·å–å¢å¼ºèµ„æº
        Args:
            resource_type: èµ„æºç±»å‹
            resource_id: èµ„æºID
            version: èµ„æºç‰ˆæœ¬
            use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜
        Returns:
            str: èµ„æºJSONå­—ç¬¦ä¸²
        """
        try:
            self._record_resource_access(f"enhanced_{resource_type}")
            
            # æ£€æŸ¥ç¼“å­˜
            cache_key = f"{resource_type}:{resource_id}:{version}"
            if use_cache and self._is_cache_valid(cache_key):
                self._enhanced_stats["cache_hits"] += 1
                cached_data = self._resource_cache[cache_key]
                logger.debug(f"Cache hit for {cache_key}")
                return json.dumps(cached_data, indent=2, ensure_ascii=False)
            
            self._enhanced_stats["cache_misses"] += 1
            
            # ç”Ÿæˆèµ„æºæ•°æ®
            resource_data = self._generate_enhanced_resource(resource_type, resource_id, version)
            
            # æ›´æ–°ç¼“å­˜
            if use_cache:
                self._update_cache(cache_key, resource_data)
            
            # è®°å½•ç‰ˆæœ¬è¯·æ±‚
            if version != "latest":
                self._enhanced_stats["version_requests"] += 1
            
            self._record_successful_access()
            
            if self.usage_monitor:
                self.usage_monitor.record_resource_access(
                    resource_name=f"enhanced_{resource_type}",
                    resource_id=resource_id,
                    version=version,
                    cache_hit=use_cache and cache_key in self._resource_cache,
                    success=True
                )
            
            return json.dumps(resource_data, indent=2, ensure_ascii=False)
            
        except Exception as e:
            self._record_failed_access()
            
            if self.usage_monitor:
                self.usage_monitor.record_resource_access(
                    resource_name=f"enhanced_{resource_type}",
                    resource_id=resource_id,
                    version=version,
                    success=False,
                    error=str(e)
                )
            
            logger.error(f"Failed to get enhanced resource {resource_type}: {e}")
            return json.dumps({"error": str(e)}, indent=2)
    
    def get_dynamic_resource(self, generator_name: str, **kwargs) -> str:
        """
        è·å–åŠ¨æ€ç”Ÿæˆçš„èµ„æº
        Args:
            generator_name: ç”Ÿæˆå™¨åç§°
            **kwargs: ç”Ÿæˆå‚æ•°
        Returns:
            str: åŠ¨æ€èµ„æºJSONå­—ç¬¦ä¸²
        """
        try:
            self._record_resource_access(f"dynamic_{generator_name}")
            
            if generator_name not in self._dynamic_generators:
                raise ValueError(f"Unknown dynamic generator: {generator_name}")
            
            # è°ƒç”¨åŠ¨æ€ç”Ÿæˆå™¨
            generator_func = self._dynamic_generators[generator_name]
            resource_data = generator_func(**kwargs)
            
            self._enhanced_stats["dynamic_generations"] += 1
            self._record_successful_access()
            
            if self.usage_monitor:
                self.usage_monitor.record_resource_access(
                    resource_name=f"dynamic_{generator_name}",
                    generator_params=kwargs,
                    success=True
                )
            
            return json.dumps(resource_data, indent=2, ensure_ascii=False)
            
        except Exception as e:
            self._record_failed_access()
            
            if self.usage_monitor:
                self.usage_monitor.record_resource_access(
                    resource_name=f"dynamic_{generator_name}",
                    generator_params=kwargs,
                    success=False,
                    error=str(e)
                )
            
            logger.error(f"Failed to generate dynamic resource {generator_name}: {e}")
            return json.dumps({"error": str(e)}, indent=2)
    
    def get_resource_recommendations(self, context: Dict[str, Any] = None) -> str:
        """
        è·å–æ™ºèƒ½èµ„æºæ¨è
        Args:
            context: æ¨èä¸Šä¸‹æ–‡
        Returns:
            str: æ¨èç»“æœJSONå­—ç¬¦ä¸²
        """
        try:
            self._record_resource_access("resource_recommendations")
            
            if not self._recommendation_engine:
                # å¦‚æœæ²¡æœ‰æ™ºèƒ½æ¨èå¼•æ“ï¼Œè¿”å›åŸºç¡€æ¨è
                recommendations = self._generate_basic_recommendations(context or {})
            else:
                recommendations = self._recommendation_engine.generate_recommendations(context or {})
            
            self._enhanced_stats["recommendations_generated"] += 1
            self._record_successful_access()
            
            if self.usage_monitor:
                self.usage_monitor.record_resource_access(
                    resource_name="resource_recommendations",
                    context=context,
                    success=True
                )
            
            return json.dumps(recommendations, indent=2, ensure_ascii=False)
            
        except Exception as e:
            self._record_failed_access()
            
            if self.usage_monitor:
                self.usage_monitor.record_resource_access(
                    resource_name="resource_recommendations",
                    context=context,
                    success=False,
                    error=str(e)
                )
            
            logger.error(f"Failed to generate resource recommendations: {e}")
            return json.dumps({"error": str(e)}, indent=2)
    
    def _generate_enhanced_resource(self, resource_type: str, resource_id: str, version: str) -> Dict[str, Any]:
        """ç”Ÿæˆå¢å¼ºèµ„æºæ•°æ®"""
        base_data = None
        
        # è·å–åŸºç¡€èµ„æºæ•°æ®
        if resource_type == "project_state":
            base_data = self._load_project_state(resource_id)
        elif resource_type == "workflow_config":
            base_data = self._load_workflow_config(resource_id)
        elif resource_type == "stage_guide":
            base_data = self._load_stage_guide(resource_id)
        else:
            raise ValueError(f"Unknown resource type: {resource_type}")
        
        # æ·»åŠ å¢å¼ºä¿¡æ¯
        enhanced_data = base_data.copy()
        enhanced_data["enhanced"] = True
        enhanced_data["enhancement_info"] = {
            "version": version,
            "generated_at": datetime.datetime.now().isoformat(),
            "cache_enabled": True,
            "intelligence_enabled": self._is_intelligence_available()
        }
        
        # æ ¹æ®èµ„æºç±»å‹æ·»åŠ ç‰¹å®šå¢å¼º
        if resource_type == "project_state":
            enhanced_data = self._enhance_project_state(enhanced_data)
        elif resource_type == "workflow_config":
            enhanced_data = self._enhance_workflow_config(enhanced_data)
        elif resource_type == "stage_guide":
            enhanced_data = self._enhance_stage_guide(enhanced_data)
        
        return enhanced_data
    
    def _enhance_project_state(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """å¢å¼ºé¡¹ç›®çŠ¶æ€æ•°æ®"""
        # æ·»åŠ è¶‹åŠ¿åˆ†æ
        data["trends"] = {
            "quality_trend": "improving",
            "progress_velocity": 0.15,  # stages per day
            "collaboration_activity": "high",
            "predicted_completion": "2024-01-15T00:00:00Z"
        }
        
        # æ·»åŠ æ™ºèƒ½æ´å¯Ÿ
        data["insights"] = [
            "Project is progressing well with good quality metrics",
            "Consider increasing test coverage for better quality",
            "Team collaboration is active and effective"
        ]
        
        # æ·»åŠ æ¨èæ“ä½œ
        data["recommended_actions"] = [
            {
                "action": "aceflow_validate",
                "priority": "high",
                "reason": "Quality score could be improved"
            },
            {
                "action": "aceflow_stage next",
                "priority": "medium", 
                "reason": "Ready to advance to testing stage"
            }
        ]
        
        return data
    
    def _enhance_workflow_config(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """å¢å¼ºå·¥ä½œæµé…ç½®æ•°æ®"""
        # æ·»åŠ æ€§èƒ½æŒ‡æ ‡
        data["performance_metrics"] = {
            "average_stage_duration": {
                "initialization": "1.5 hours",
                "planning": "3 hours", 
                "implementation": "2-5 days",
                "testing": "2 hours",
                "deployment": "1 hour"
            },
            "success_rates": {
                "initialization": 0.98,
                "planning": 0.95,
                "implementation": 0.87,
                "testing": 0.92,
                "deployment": 0.96
            }
        }
        
        # æ·»åŠ ä¼˜åŒ–å»ºè®®
        data["optimization_suggestions"] = [
            "Consider parallel testing during implementation",
            "Automate deployment process for faster delivery",
            "Add code review checkpoints in implementation"
        ]
        
        return data
    
    def _enhance_stage_guide(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """å¢å¼ºé˜¶æ®µæŒ‡å¯¼æ•°æ®"""
        # æ·»åŠ ç›¸å…³èµ„æºé“¾æ¥
        data["related_resources"] = [
            {
                "type": "documentation",
                "title": f"{data['stage'].title()} Best Practices",
                "url": f"/docs/{data['stage']}-best-practices"
            },
            {
                "type": "template",
                "title": f"{data['stage'].title()} Checklist",
                "url": f"/templates/{data['stage']}-checklist"
            }
        ]
        
        # æ·»åŠ äº¤äº’å¼å…ƒç´ 
        data["interactive_elements"] = [
            {
                "type": "checklist",
                "title": "Stage Completion Checklist",
                "items": [step["title"] for step in data.get("steps", [])]
            },
            {
                "type": "progress_tracker",
                "title": "Stage Progress",
                "current_step": 1,
                "total_steps": len(data.get("steps", []))
            }
        ]
        
        return data
    
    # Dynamic Resource Generators
    def _generate_project_insights(self, project_id: str = "current", **kwargs) -> Dict[str, Any]:
        """ç”Ÿæˆé¡¹ç›®æ´å¯Ÿ"""
        return {
            "resource_type": "project_insights",
            "project_id": project_id,
            "insights": {
                "quality_analysis": {
                    "current_score": 0.82,
                    "trend": "improving",
                    "key_areas": ["test_coverage", "documentation", "code_quality"]
                },
                "progress_analysis": {
                    "velocity": 0.15,
                    "predicted_completion": "2024-01-15",
                    "risk_factors": ["dependency_delays", "resource_constraints"]
                },
                "team_analysis": {
                    "productivity": "high",
                    "collaboration_score": 0.89,
                    "bottlenecks": ["code_review_delays"]
                }
            },
            "recommendations": [
                "Focus on improving test coverage",
                "Streamline code review process",
                "Consider adding more documentation"
            ],
            "generated_at": datetime.datetime.now().isoformat()
        }
    
    def _generate_workflow_analytics(self, timeframe: str = "30d", **kwargs) -> Dict[str, Any]:
        """ç”Ÿæˆå·¥ä½œæµåˆ†æ"""
        return {
            "resource_type": "workflow_analytics",
            "timeframe": timeframe,
            "analytics": {
                "stage_performance": {
                    "initialization": {"avg_duration": "1.2h", "success_rate": 0.98},
                    "planning": {"avg_duration": "2.8h", "success_rate": 0.95},
                    "implementation": {"avg_duration": "3.2d", "success_rate": 0.87},
                    "testing": {"avg_duration": "1.8h", "success_rate": 0.92},
                    "deployment": {"avg_duration": "45m", "success_rate": 0.96}
                },
                "bottlenecks": [
                    {"stage": "implementation", "issue": "code_complexity", "impact": "high"},
                    {"stage": "testing", "issue": "test_environment_setup", "impact": "medium"}
                ],
                "efficiency_metrics": {
                    "overall_throughput": 0.73,
                    "stage_transition_time": "15m",
                    "rework_rate": 0.12
                }
            },
            "trends": {
                "quality_improvement": 0.08,
                "speed_improvement": 0.05,
                "team_satisfaction": 0.85
            },
            "generated_at": datetime.datetime.now().isoformat()
        }
    
    def _generate_stage_recommendations(self, current_stage: str = "implementation", **kwargs) -> Dict[str, Any]:
        """ç”Ÿæˆé˜¶æ®µæ¨è"""
        recommendations_map = {
            "initialization": [
                {"action": "setup_ci_cd", "priority": "high", "benefit": "automation"},
                {"action": "create_documentation", "priority": "medium", "benefit": "clarity"}
            ],
            "planning": [
                {"action": "stakeholder_review", "priority": "high", "benefit": "alignment"},
                {"action": "risk_assessment", "priority": "medium", "benefit": "preparation"}
            ],
            "implementation": [
                {"action": "code_review", "priority": "high", "benefit": "quality"},
                {"action": "unit_testing", "priority": "high", "benefit": "reliability"}
            ],
            "testing": [
                {"action": "integration_testing", "priority": "high", "benefit": "stability"},
                {"action": "performance_testing", "priority": "medium", "benefit": "scalability"}
            ],
            "deployment": [
                {"action": "backup_creation", "priority": "high", "benefit": "safety"},
                {"action": "monitoring_setup", "priority": "medium", "benefit": "observability"}
            ]
        }
        
        return {
            "resource_type": "stage_recommendations",
            "current_stage": current_stage,
            "recommendations": recommendations_map.get(current_stage, []),
            "next_stage_preparation": [
                "Review current stage deliverables",
                "Prepare for next stage requirements",
                "Update project documentation"
            ],
            "best_practices": [
                f"Follow {current_stage} stage guidelines",
                "Maintain quality standards",
                "Communicate progress regularly"
            ],
            "generated_at": datetime.datetime.now().isoformat()
        }
    
    def _generate_quality_trends(self, project_id: str = "current", **kwargs) -> Dict[str, Any]:
        """ç”Ÿæˆè´¨é‡è¶‹åŠ¿"""
        return {
            "resource_type": "quality_trends",
            "project_id": project_id,
            "trends": {
                "overall_quality": {
                    "current": 0.82,
                    "previous": 0.78,
                    "trend": "improving",
                    "change_rate": 0.05
                },
                "metrics": {
                    "test_coverage": {"current": 0.75, "target": 0.80, "trend": "improving"},
                    "code_quality": {"current": 0.85, "target": 0.90, "trend": "stable"},
                    "documentation": {"current": 0.70, "target": 0.85, "trend": "improving"}
                }
            },
            "predictions": {
                "next_week": 0.84,
                "next_month": 0.87,
                "confidence": 0.78
            },
            "improvement_areas": [
                {"area": "test_coverage", "priority": "high", "effort": "medium"},
                {"area": "documentation", "priority": "medium", "effort": "low"}
            ],
            "generated_at": datetime.datetime.now().isoformat()
        }
    
    def _generate_collaboration_metrics(self, team_id: str = "default", **kwargs) -> Dict[str, Any]:
        """ç”Ÿæˆåä½œæŒ‡æ ‡"""
        return {
            "resource_type": "collaboration_metrics",
            "team_id": team_id,
            "metrics": {
                "team_activity": {
                    "active_members": 3,
                    "daily_commits": 12,
                    "code_reviews": 8,
                    "discussions": 15
                },
                "collaboration_score": 0.89,
                "communication_patterns": {
                    "response_time": "2.3h",
                    "meeting_frequency": "daily",
                    "knowledge_sharing": "high"
                }
            },
            "team_health": {
                "productivity": 0.87,
                "satisfaction": 0.85,
                "workload_balance": 0.78
            },
            "recommendations": [
                "Continue current collaboration practices",
                "Consider async communication for non-urgent items",
                "Schedule regular team retrospectives"
            ],
            "generated_at": datetime.datetime.now().isoformat()
        }
    
    def _generate_basic_recommendations(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """ç”ŸæˆåŸºç¡€æ¨è"""
        return {
            "recommendations": [
                {
                    "type": "resource",
                    "resource": "project_state",
                    "reason": "Check current project status",
                    "priority": "high"
                },
                {
                    "type": "resource", 
                    "resource": "workflow_config",
                    "reason": "Review workflow configuration",
                    "priority": "medium"
                },
                {
                    "type": "resource",
                    "resource": "stage_guide",
                    "reason": "Get guidance for current stage",
                    "priority": "medium"
                }
            ],
            "context_used": context,
            "generated_at": datetime.datetime.now().isoformat(),
            "recommendation_engine": "basic"
        }
    
    # Cache Management
    def _is_cache_valid(self, cache_key: str) -> bool:
        """æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ"""
        if cache_key not in self._resource_cache:
            return False
        if cache_key not in self._cache_timestamps:
            return False
        
        cache_time = self._cache_timestamps[cache_key]
        current_time = datetime.datetime.now()
        return (current_time - cache_time).total_seconds() < self._cache_ttl
    
    def _update_cache(self, cache_key: str, data: Dict[str, Any]):
        """æ›´æ–°ç¼“å­˜"""
        self._resource_cache[cache_key] = data
        self._cache_timestamps[cache_key] = datetime.datetime.now()
    
    def clear_cache(self, resource_type: str = None):
        """æ¸…ç†ç¼“å­˜"""
        if resource_type:
            # æ¸…ç†ç‰¹å®šç±»å‹çš„ç¼“å­˜
            keys_to_remove = [key for key in self._resource_cache.keys() if key.startswith(resource_type)]
            for key in keys_to_remove:
                del self._resource_cache[key]
                if key in self._cache_timestamps:
                    del self._cache_timestamps[key]
        else:
            # æ¸…ç†æ‰€æœ‰ç¼“å­˜
            self._resource_cache.clear()
            self._cache_timestamps.clear()
        
        logger.info(f"Cache cleared for {resource_type or 'all resources'}")
    
    # Utility Methods
    def _is_intelligence_available(self) -> bool:
        """æ£€æŸ¥æ™ºèƒ½æ¨¡å—æ˜¯å¦å¯ç”¨"""
        intel_module = self.module_manager.get_module("intelligence")
        return intel_module and intel_module.is_available()
    
    def get_enhanced_stats(self) -> Dict[str, Any]:
        """è·å–å¢å¼ºç»Ÿè®¡ä¿¡æ¯"""
        base_stats = self.get_resource_stats()
        base_stats.update(self._enhanced_stats)
        base_stats["cache_info"] = {
            "cache_size": len(self._resource_cache),
            "cache_hit_rate": self._enhanced_stats["cache_hits"] / max(1, self._enhanced_stats["cache_hits"] + self._enhanced_stats["cache_misses"]),
            "cache_ttl": self._cache_ttl
        }
        return base_stats
    
    def reset_enhanced_stats(self):
        """é‡ç½®å¢å¼ºç»Ÿè®¡ä¿¡æ¯"""
        self.reset_stats()
        self._enhanced_stats = {
            "cache_hits": 0,
            "cache_misses": 0,
            "dynamic_generations": 0,
            "recommendations_generated": 0,
            "version_requests": 0
        }
        logger.info("Enhanced statistics reset")


class ResourceRecommendationEngine:
    """èµ„æºæ¨èå¼•æ“"""
    
    def __init__(self, config):
        self.config = config
    
    def generate_recommendations(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆæ™ºèƒ½æ¨è"""
        current_stage = context.get("current_stage", "unknown")
        project_quality = context.get("quality_score", 0.5)
        team_size = context.get("team_size", 1)
        
        recommendations = []
        
        # åŸºäºå½“å‰é˜¶æ®µçš„æ¨è
        if current_stage == "initialization":
            recommendations.extend([
                {"type": "resource", "resource": "workflow_config", "priority": "high", "reason": "Setup workflow"},
                {"type": "resource", "resource": "stage_guide", "priority": "high", "reason": "Get initialization guidance"}
            ])
        elif current_stage == "implementation":
            recommendations.extend([
                {"type": "dynamic", "resource": "quality_trends", "priority": "high", "reason": "Monitor quality"},
                {"type": "resource", "resource": "project_state", "priority": "medium", "reason": "Track progress"}
            ])
        
        # åŸºäºè´¨é‡åˆ†æ•°çš„æ¨è
        if project_quality < 0.7:
            recommendations.append({
                "type": "dynamic", 
                "resource": "quality_trends", 
                "priority": "high", 
                "reason": "Quality improvement needed"
            })
        
        # åŸºäºå›¢é˜Ÿè§„æ¨¡çš„æ¨è
        if team_size > 1:
            recommendations.append({
                "type": "dynamic",
                "resource": "collaboration_metrics",
                "priority": "medium",
                "reason": "Team collaboration insights"
            })
        
        return {
            "recommendations": recommendations,
            "context_used": context,
            "generated_at": datetime.datetime.now().isoformat(),
            "recommendation_engine": "intelligent"
        }


# Enhanced Resource Interface Tests
def test_enhanced_resources_initialization():
    """æµ‹è¯•å¢å¼ºèµ„æºæ¥å£åˆå§‹åŒ–"""
    print("ğŸ§ª Testing enhanced resources interface initialization...")
    
    config = MockConfig()
    module_manager = MockModuleManager()
    usage_monitor = MockUsageMonitor()
    
    enhanced_resources = EnhancedResourcesInterface(config, module_manager, usage_monitor)
    
    # éªŒè¯åˆå§‹åŒ–
    assert enhanced_resources.config == config
    assert enhanced_resources.module_manager == module_manager
    assert enhanced_resources.usage_monitor == usage_monitor
    
    # éªŒè¯å¢å¼ºåŠŸèƒ½åˆå§‹åŒ–
    assert hasattr(enhanced_resources, '_resource_cache')
    assert hasattr(enhanced_resources, '_dynamic_generators')
    assert hasattr(enhanced_resources, '_enhanced_stats')
    
    # éªŒè¯åŠ¨æ€ç”Ÿæˆå™¨æ³¨å†Œ
    assert len(enhanced_resources._dynamic_generators) > 0
    assert "project_insights" in enhanced_resources._dynamic_generators
    assert "workflow_analytics" in enhanced_resources._dynamic_generators
    
    print("âœ… Enhanced resources interface initialization test passed")


def test_enhanced_resource_with_cache():
    """æµ‹è¯•å¸¦ç¼“å­˜çš„å¢å¼ºèµ„æº"""
    print("ğŸ§ª Testing enhanced resource with cache...")
    
    config = MockConfig()
    module_manager = MockModuleManager()
    usage_monitor = MockUsageMonitor()
    
    enhanced_resources = EnhancedResourcesInterface(config, module_manager, usage_monitor)
    
    # ç¬¬ä¸€æ¬¡è®¿é—®ï¼ˆç¼“å­˜æœªå‘½ä¸­ï¼‰
    resource_json = enhanced_resources.get_enhanced_resource("project_state", "test-project")
    resource_data = json.loads(resource_json)
    
    # éªŒè¯å¢å¼ºæ•°æ®
    assert "enhanced" in resource_data
    assert resource_data["enhanced"] == True
    assert "enhancement_info" in resource_data
    assert "trends" in resource_data
    assert "insights" in resource_data
    assert "recommended_actions" in resource_data
    
    # éªŒè¯ç¼“å­˜ç»Ÿè®¡
    stats = enhanced_resources.get_enhanced_stats()
    assert stats["cache_misses"] == 1
    assert stats["cache_hits"] == 0
    
    # ç¬¬äºŒæ¬¡è®¿é—®ï¼ˆç¼“å­˜å‘½ä¸­ï¼‰
    resource_json2 = enhanced_resources.get_enhanced_resource("project_state", "test-project")
    resource_data2 = json.loads(resource_json2)
    
    # éªŒè¯ç¼“å­˜å‘½ä¸­
    stats = enhanced_resources.get_enhanced_stats()
    assert stats["cache_hits"] == 1
    assert stats["cache_misses"] == 1
    
    print("âœ… Enhanced resource with cache test passed")


def test_dynamic_resource_generation():
    """æµ‹è¯•åŠ¨æ€èµ„æºç”Ÿæˆ"""
    print("ğŸ§ª Testing dynamic resource generation...")
    
    config = MockConfig()
    module_manager = MockModuleManager()
    usage_monitor = MockUsageMonitor()
    
    enhanced_resources = EnhancedResourcesInterface(config, module_manager, usage_monitor)
    
    # æµ‹è¯•é¡¹ç›®æ´å¯Ÿç”Ÿæˆ
    insights_json = enhanced_resources.get_dynamic_resource("project_insights", project_id="test-project")
    insights_data = json.loads(insights_json)
    
    assert insights_data["resource_type"] == "project_insights"
    assert insights_data["project_id"] == "test-project"
    assert "insights" in insights_data
    assert "recommendations" in insights_data
    
    # æµ‹è¯•å·¥ä½œæµåˆ†æç”Ÿæˆ
    analytics_json = enhanced_resources.get_dynamic_resource("workflow_analytics", timeframe="7d")
    analytics_data = json.loads(analytics_json)
    
    assert analytics_data["resource_type"] == "workflow_analytics"
    assert analytics_data["timeframe"] == "7d"
    assert "analytics" in analytics_data
    assert "trends" in analytics_data
    
    # éªŒè¯ç»Ÿè®¡
    stats = enhanced_resources.get_enhanced_stats()
    assert stats["dynamic_generations"] == 2
    
    print("âœ… Dynamic resource generation test passed")


def test_resource_recommendations():
    """æµ‹è¯•èµ„æºæ¨è"""
    print("ğŸ§ª Testing resource recommendations...")
    
    config = MockConfig()
    module_manager = MockModuleManager()
    usage_monitor = MockUsageMonitor()
    
    enhanced_resources = EnhancedResourcesInterface(config, module_manager, usage_monitor)
    
    # æµ‹è¯•åŸºç¡€æ¨è
    context = {
        "current_stage": "implementation",
        "quality_score": 0.6,
        "team_size": 3
    }
    
    recommendations_json = enhanced_resources.get_resource_recommendations(context)
    recommendations_data = json.loads(recommendations_json)
    
    assert "recommendations" in recommendations_data
    assert "context_used" in recommendations_data
    assert len(recommendations_data["recommendations"]) > 0
    
    # éªŒè¯æ¨èå†…å®¹
    recommendations = recommendations_data["recommendations"]
    has_quality_recommendation = any(
        rec.get("reason") == "Quality improvement needed" 
        for rec in recommendations
    )
    assert has_quality_recommendation  # å› ä¸ºè´¨é‡åˆ†æ•° < 0.7
    
    # éªŒè¯ç»Ÿè®¡
    stats = enhanced_resources.get_enhanced_stats()
    assert stats["recommendations_generated"] == 1
    
    print("âœ… Resource recommendations test passed")


def test_cache_management():
    """æµ‹è¯•ç¼“å­˜ç®¡ç†"""
    print("ğŸ§ª Testing cache management...")
    
    config = MockConfig()
    module_manager = MockModuleManager()
    
    enhanced_resources = EnhancedResourcesInterface(config, module_manager)
    
    # æ·»åŠ ä¸€äº›ç¼“å­˜æ•°æ®
    enhanced_resources.get_enhanced_resource("project_state", "project1")
    enhanced_resources.get_enhanced_resource("workflow_config", "config1")
    
    # éªŒè¯ç¼“å­˜å­˜åœ¨
    assert len(enhanced_resources._resource_cache) == 2
    
    # æ¸…ç†ç‰¹å®šç±»å‹çš„ç¼“å­˜
    enhanced_resources.clear_cache("project_state")
    
    # éªŒè¯éƒ¨åˆ†æ¸…ç†
    remaining_keys = list(enhanced_resources._resource_cache.keys())
    assert len(remaining_keys) == 1
    assert remaining_keys[0].startswith("workflow_config")
    
    # æ¸…ç†æ‰€æœ‰ç¼“å­˜
    enhanced_resources.clear_cache()
    assert len(enhanced_resources._resource_cache) == 0
    
    print("âœ… Cache management test passed")


async def test_enhanced_resources():
    """è¿è¡Œå¢å¼ºèµ„æºæ¥å£æµ‹è¯•"""
    print("ğŸš€ Starting enhanced resources interface tests...\n")
    
    try:
        test_enhanced_resources_initialization()
        test_enhanced_resource_with_cache()
        test_dynamic_resource_generation()
        test_resource_recommendations()
        test_cache_management()
        
        print("\nğŸ‰ All enhanced resources interface tests passed!")
        print("\nğŸ“Š Enhanced Resources Interface Summary:")
        print("   âœ… Enhanced Interface Initialization - Working")
        print("   âœ… Resource Caching - Working")
        print("   âœ… Dynamic Resource Generation - Working")
        print("   âœ… Intelligent Recommendations - Working")
        print("   âœ… Cache Management - Working")
        
    except Exception as e:
        print(f"\nâŒ Enhanced resources interface test failed: {e}")
        raise


if __name__ == "__main__":
    # è¿è¡ŒåŸºç¡€æµ‹è¯•
    success = asyncio.run(main())
    
    if success:
        # è¿è¡Œå¢å¼ºæµ‹è¯•
        try:
            asyncio.run(test_enhanced_resources())
            print("\nğŸ—ï¸ Task 5.2 - Enhanced Resources Interface Implementation Complete!")
        except Exception as e:
            print(f"\nâŒ Enhanced resources test failed: {e}")
            success = False
    
    sys.exit(0 if success else 1)